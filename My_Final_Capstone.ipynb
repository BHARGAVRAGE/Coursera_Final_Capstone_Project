{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "<a href=\"https://www.bigdatauniversity.com\"><img src=\"https://ibm.box.com/shared/static/cw2c7r3o20w9zn8gkecaeyjhgw3xdgbj.png\" width=\"400\" align=\"center\"></a>\n\n<h1 align=\"center\"><font size=\"5\">Classification with Python</font></h1>"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "In this notebook we try to practice all the classification algorithms that we learned in this course.\n\nWe load a dataset using Pandas library, and apply the following algorithms, and find the best one for this specific dataset by accuracy evaluation methods.\n\nLets first load required libraries:"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "outputs": [],
            "source": "import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import NullFormatter\nimport pandas as pd\nimport numpy as np\nimport matplotlib.ticker as ticker\nfrom sklearn import preprocessing\n%matplotlib inline"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "### About dataset"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "This dataset is about past loans. The __Loan_train.csv__ data set includes details of 346 customers whose loan are already paid off or defaulted. It includes following fields:\n\n| Field          | Description                                                                           |\n|----------------|---------------------------------------------------------------------------------------|\n| Loan_status    | Whether a loan is paid off on in collection                                           |\n| Principal      | Basic principal loan amount at the                                                    |\n| Terms          | Origination terms which can be weekly (7 days), biweekly, and monthly payoff schedule |\n| Effective_date | When the loan got originated and took effects                                         |\n| Due_date       | Since it\u2019s one-time payoff schedule, each loan has one single due date                |\n| Age            | Age of applicant                                                                      |\n| Education      | Education of applicant                                                                |\n| Gender         | The gender of applicant                                                               |"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "Lets download the dataset"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                },
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "--2020-03-16 14:01:20--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_train.csv\nResolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\nConnecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 23101 (23K) [text/csv]\nSaving to: \u2018loan_train.csv\u2019\n\n100%[======================================>] 23,101      --.-K/s   in 0.002s  \n\n2020-03-16 14:01:20 (11.9 MB/s) - \u2018loan_train.csv\u2019 saved [23101/23101]\n\n"
                }
            ],
            "source": "!wget -O loan_train.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_train.csv"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "### Load Data From CSV File  "
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 0.1</th>\n      <th>loan_status</th>\n      <th>Principal</th>\n      <th>terms</th>\n      <th>effective_date</th>\n      <th>due_date</th>\n      <th>age</th>\n      <th>education</th>\n      <th>Gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>9/8/2016</td>\n      <td>10/7/2016</td>\n      <td>45</td>\n      <td>High School or Below</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>9/8/2016</td>\n      <td>10/7/2016</td>\n      <td>33</td>\n      <td>Bechalor</td>\n      <td>female</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>15</td>\n      <td>9/8/2016</td>\n      <td>9/22/2016</td>\n      <td>27</td>\n      <td>college</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>9/9/2016</td>\n      <td>10/8/2016</td>\n      <td>28</td>\n      <td>college</td>\n      <td>female</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>6</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>9/9/2016</td>\n      <td>10/8/2016</td>\n      <td>29</td>\n      <td>college</td>\n      <td>male</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   Unnamed: 0  Unnamed: 0.1 loan_status  Principal  terms effective_date  \\\n0           0             0     PAIDOFF       1000     30       9/8/2016   \n1           2             2     PAIDOFF       1000     30       9/8/2016   \n2           3             3     PAIDOFF       1000     15       9/8/2016   \n3           4             4     PAIDOFF       1000     30       9/9/2016   \n4           6             6     PAIDOFF       1000     30       9/9/2016   \n\n    due_date  age             education  Gender  \n0  10/7/2016   45  High School or Below    male  \n1  10/7/2016   33              Bechalor  female  \n2  9/22/2016   27               college    male  \n3  10/8/2016   28               college  female  \n4  10/8/2016   29               college    male  "
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df = pd.read_csv('loan_train.csv')\ndf.head()"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "(346, 10)\n"
                }
            ],
            "source": "print(df.shape)"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "### Convert to date time object "
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 0.1</th>\n      <th>loan_status</th>\n      <th>Principal</th>\n      <th>terms</th>\n      <th>effective_date</th>\n      <th>due_date</th>\n      <th>age</th>\n      <th>education</th>\n      <th>Gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>2016-09-08</td>\n      <td>2016-10-07</td>\n      <td>45</td>\n      <td>High School or Below</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>2016-09-08</td>\n      <td>2016-10-07</td>\n      <td>33</td>\n      <td>Bechalor</td>\n      <td>female</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>15</td>\n      <td>2016-09-08</td>\n      <td>2016-09-22</td>\n      <td>27</td>\n      <td>college</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>2016-09-09</td>\n      <td>2016-10-08</td>\n      <td>28</td>\n      <td>college</td>\n      <td>female</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>6</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>2016-09-09</td>\n      <td>2016-10-08</td>\n      <td>29</td>\n      <td>college</td>\n      <td>male</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   Unnamed: 0  Unnamed: 0.1 loan_status  Principal  terms effective_date  \\\n0           0             0     PAIDOFF       1000     30     2016-09-08   \n1           2             2     PAIDOFF       1000     30     2016-09-08   \n2           3             3     PAIDOFF       1000     15     2016-09-08   \n3           4             4     PAIDOFF       1000     30     2016-09-09   \n4           6             6     PAIDOFF       1000     30     2016-09-09   \n\n    due_date  age             education  Gender  \n0 2016-10-07   45  High School or Below    male  \n1 2016-10-07   33              Bechalor  female  \n2 2016-09-22   27               college    male  \n3 2016-10-08   28               college  female  \n4 2016-10-08   29               college    male  "
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df['due_date'] = pd.to_datetime(df['due_date'])\ndf['effective_date'] = pd.to_datetime(df['effective_date'])\ndf.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "# Data visualization and pre-processing\n\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "Let\u2019s see how many of each class is in our data set "
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "PAIDOFF       260\nCOLLECTION     86\nName: loan_status, dtype: int64"
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df['loan_status'].value_counts()"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "260 people have paid off the loan on time while 86 have gone into collection \n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Lets plot some columns to underestand data better:"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": "<Figure size 432x216 with 2 Axes>"
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": "import seaborn as sns\n\nbins = np.linspace(df.Principal.min(), df.Principal.max(), 10)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'Principal', bins=bins, ec=\"k\")\n\ng.axes[-1].legend()\nplt.show()"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "outputs": [
                {
                    "data": {
                        "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAADQCAYAAABStPXYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAGfZJREFUeJzt3XuQVOW57/HvTxgdFbygo4yMwKgoopIBZ3tDDYJy2N49XuKOR7GOJx4Naqjo8ZZTVrLdZbyVmhwvkUQLK1HUmA26SUWDCidi4gVwRBBv0UFHQS7RKAchgs/5o9fMHqBhembWTK/u+X2qVnWvt1e/61lMvzy93vX2uxQRmJmZZc02xQ7AzMwsHycoMzPLJCcoMzPLJCcoMzPLJCcoMzPLJCcoMzPLJCeolEjaU9Ijkt6XNE/SXySdkVLdoyXNSKOu7iBptqT6YsdhxVdO7UJSlaSXJb0m6Zgu3M/qrqq71DhBpUCSgOnAnyJin4g4FDgXqClSPL2LsV+z1sqwXYwF3oqIERHxQhox2dY5QaVjDPCPiPhFc0FELImI/wMgqZek2yS9KmmBpP+ZlI9OzjaekPSWpIeTRo2k8UnZHOC/NtcraUdJDyZ1vSbptKT8Qkm/lfQfwB87czCSpki6T9Ks5Jvvt5N9LpY0pdV290maK2mRpJ9soa5xybfm+Ul8fToTm5WUsmkXkuqAW4ETJTVI2n5Ln21JjZJuSl6bK2mkpGck/VXSJck2fSQ9l7z3jeZ48+z3f7X698nbxspaRHjp5AJcAdy5ldcvBv538nw7YC5QC4wG/k7uG+U2wF+Ao4FK4CNgCCDgcWBG8v6bgP+WPN8FeAfYEbgQaAL6bSGGF4CGPMvxebadAjya7Ps04AvgkCTGeUBdsl2/5LEXMBsYnqzPBuqB3YE/ATsm5dcANxT77+Wle5YybBcXAncnz7f42QYagUuT53cCC4C+QBWwPCnvDezUqq73ACXrq5PHccDk5Fi3AWYAxxb779qdi7uCuoCke8g1qH9ExD+R+6ANl3RWssnO5BrZP4BXIqIpeV8DMBhYDXwQEe8m5b8h15hJ6jpV0lXJeiUwMHk+MyL+li+miGhvn/l/RERIegP4NCLeSGJZlMTYAJwj6WJyja0aGEauMTY7Iil7MfkCvC25/2ysByqTdtGsrc/2U8njG0CfiPgS+FLSWkm7AP8PuEnSscA3wABgT2BZqzrGJctryXofcv8+f+pgzCXHCSodi4Azm1ciYqKk3cl9I4TcN6DLI+KZ1m+SNBpY16poA//5N9nSJIkCzoyItzep63ByH/r8b5JeIPctblNXRcSzecqb4/pmkxi/AXpLqgWuAv4pIj5Luv4q88Q6MyL+ZUtxWVkrx3bRen9b+2xvtf0A55E7ozo0Ir6W1Ej+9vPTiLh/K3GUNV+DSsfzQKWkS1uV7dDq+TPApZIqACTtL2nHrdT3FlArad9kvXUjeAa4vFWf/IhCAoyIYyKiLs+ytUa4NTuRa/h/l7Qn8M95tnkJGCVpvyTWHSTt38H9Wekp53bR2c/2zuS6+76WdBwwKM82zwD/vdW1rQGS9mjHPkqeE1QKItdhfDrwbUkfSHoFeIhcvzTAr4A3gfmSFgL3s5Wz14hYS67r4vfJxeAlrV6+EagAFiR13Zj28RQiIl4n1/WwCHgQeDHPNivI9dtPlbSAXKMe2o1hWhGVc7tI4bP9MFAvaS65s6m38uzjj8AjwF+SrvYnyH+2V7aaL8qZmZllis+gzMwsk5ygzMwsk5ygzMwsk5ygzMwsk7o1QY0fPz7I/Y7Bi5dyXTrN7cRLD1gK0q0JauXKld25O7OS5HZiluMuPjMzyyQnKDMzyyQnKDMzyyRPFmtmZefrr7+mqamJtWvXFjuUHq2yspKamhoqKio69H4nKDMrO01NTfTt25fBgweTzB9r3SwiWLVqFU1NTdTW1naoDnfxmVnZWbt2LbvttpuTUxFJYrfdduvUWawTVDcaVF2NpFSWQdXVxT4cs0xzciq+zv4N3MXXjT5ctoymvWpSqavmk6ZU6jEzyyqfQZlZ2Uuz96LQHoxevXpRV1fHwQcfzNlnn82aNWtaXps2bRqSeOut/7wNVGNjIwcffDAAs2fPZuedd2bEiBEccMABHHvsscyYMWOj+idPnszQoUMZOnQohx12GHPmzGl5bfTo0RxwwAHU1dVRV1fHE088sVFMzUtjY2Nn/lm7nM+gzKzspdl7AYX1YGy//fY0NDQAcN555/GLX/yCH/7whwBMnTqVo48+mkcffZQf//jHed9/zDHHtCSlhoYGTj/9dLbffnvGjh3LjBkzuP/++5kzZw6777478+fP5/TTT+eVV16hf//+ADz88MPU19dvMaZS4DMoM7Mudswxx/Dee+8BsHr1al588UUeeOABHn300YLeX1dXxw033MDdd98NwC233MJtt93G7rvvDsDIkSOZMGEC99xzT9ccQJE4QZmZdaH169fzhz/8gUMOOQSA6dOnM378ePbff3/69evH/PnzC6pn5MiRLV2CixYt4tBDD93o9fr6ehYtWtSyft5557V05a1atQqAr776qqXsjDPOSOPwupS7+MzMukBzMoDcGdRFF10E5Lr3Jk2aBMC5557L1KlTGTlyZJv1RWx9EvCI2GjUXDl08RWUoCQ1Al8CG4D1EVEvqR/wGDAYaATOiYjPuiZMM7PSki8ZrFq1iueff56FCxciiQ0bNiCJW2+9tc36XnvtNQ488EAAhg0bxrx58xgzZkzL6/Pnz2fYsGHpHkSRtaeL77iIqIuI5pR8LfBcRAwBnkvWzcxsC5544gkuuOAClixZQmNjIx999BG1tbUbjcDLZ8GCBdx4441MnDgRgKuvvpprrrmmpeuuoaGBKVOm8P3vf7/Lj6E7daaL7zRgdPL8IWA2cE0n4zEzS93A/v1T/e3gwGSkXHtNnTqVa6/d+Lv8mWeeySOPPMI112z83+cLL7zAiBEjWLNmDXvssQc///nPGTt2LACnnnoqH3/8MUcddRSS6Nu3L7/5zW+oLrMf8Kutfk0ASR8An5G7E+L9ETFZ0ucRsUurbT6LiF3zvPdi4GKAgQMHHrpkyZLUgi81klL9oW4hfzvrdh366bzbSboWL17c0h1mxbWFv0VB7aTQLr5RETES+GdgoqRjCw0uIiZHRH1E1FdVVRX6NrMexe3EbHMFJaiI+CR5XA5MAw4DPpVUDZA8Lu+qIM3MrOdpM0FJ2lFS3+bnwDhgIfAUMCHZbALwZFcFaWZmPU8hgyT2BKYl4+t7A49ExNOSXgUel3QR8CFwdteFaWZmPU2bCSoi3ge+lad8FTC2K4IyMzPzVEdmZpZJTlBmVvb2qhmY6u029qoZWNB+ly1bxrnnnsu+++7LsGHDOPHEE3nnnXdYtGgRY8aMYf/992fIkCHceOONLT8bmTJlCpdddtlmdQ0ePJiVK1duVDZlyhSqqqo2uoXGm2++CcA777zDiSeeyH777ceBBx7IOeecw2OPPdayXZ8+fVpuyXHBBRcwe/ZsTj755Ja6p0+fzvDhwxk6dCiHHHII06dPb3ntwgsvZMCAAaxbtw6AlStXMnjw4Hb9TQrhufgKMKi6mg+XLSt2GGbWQUs//ojDb3g6tfpe/tfxbW4TEZxxxhlMmDChZdbyhoYGPv30Uy688ELuu+8+xo0bx5o1azjzzDO59957W2aKaI/vfOc7LbOcN1u7di0nnXQSd9xxB6eccgoAs2bNoqqqqmX6pdGjR3P77be3zNc3e/bslve//vrrXHXVVcycOZPa2lo++OADTjjhBPbZZx+GDx8O5O4t9eCDD3LppZe2O+ZCOUEVIK17yfguuGY9x6xZs6ioqOCSSy5pKaurq+OBBx5g1KhRjBs3DoAddtiBu+++m9GjR3coQeXzyCOPcOSRR7YkJ4Djjjuu4PfffvvtXH/99dTW1gJQW1vLddddx2233cavf/1rACZNmsSdd97J9773vVRizsddfGZmXWDhwoWb3RID8t8qY99992X16tV88cUX7d5P6267uro6vvrqqy3uu1CF3M5j4MCBHH300S0Jqyv4DMrMrBtteluM1rZUvjX5uvg6K1+M+cquv/56Tj31VE466aRU99/MZ1BmZl3goIMOYt68eXnL586du1HZ+++/T58+fejbt2+X7rs97980xny389hvv/2oq6vj8ccf7/C+tsYJysysC4wZM4Z169bxy1/+sqXs1VdfZciQIcyZM4dnn30WyN3Y8IorruDqq69Obd/f/e53+fOf/8zvf//7lrKnn36aN954o6D3X3XVVfz0pz+lsbERgMbGRm666SauvPLKzbb90Y9+xO23355K3JtyF5+Zlb3qAXsXNPKuPfW1RRLTpk1j0qRJ3HzzzVRWVjJ48GDuuusunnzySS6//HImTpzIhg0bOP/88zcaWj5lypSNhnW/9NJLAAwfPpxttsmdV5xzzjkMHz6cxx57bKP7Sd17770cddRRzJgxg0mTJjFp0iQqKioYPnw4P/vZzwo6vrq6Om655RZOOeUUvv76ayoqKrj11ltb7hDc2kEHHcTIkSMLvnV9exR0u4201NfXx6anjaUgrdtk1HzS5NttlL8O3W6jtVJtJ1ni221kR3fcbsPMzKxbOUGZmVkmOUGZWVlyF3jxdfZv4ARlZmWnsrKSVatWOUkVUUSwatUqKisrO1yHR/GZWdmpqamhqamJFStWFDuUHq2yspKamo4PDHOCKlHb0bFfneczsH9/lixdmkpdZllQUVHRMo+clS4nqBK1DlIdsm5mljUFX4OS1EvSa5JmJOu1kl6W9K6kxyRt23VhmplZT9OeQRI/ABa3Wr8FuDMihgCfARelGZiZmfVsBSUoSTXAScCvknUBY4Ankk0eAk7vigDNzKxnKvQM6i7gauCbZH034POIWJ+sNwED8r1R0sWS5kqa6xE1Zvm5nZhtrs0EJelkYHlEtJ67Pd/wsbw/OIiIyRFRHxH1VVVVHQzTrLy5nZhtrpBRfKOAUyWdCFQCO5E7o9pFUu/kLKoG+KTrwjQzs56mzTOoiLguImoiYjBwLvB8RJwHzALOSjabADzZZVGamVmP05mpjq4BfijpPXLXpB5IJyQzM7N2/lA3ImYDs5Pn7wOHpR+SmZmZJ4s1M7OMcoIyM7NMcoIyM7NMcoIyM7NMcoIyM7NMcoIyM7NMcoIyM7NMcoIyM7NMcoIyM7NMcoIyM7NMcoIyM7NMcoIyM7NMcoIyM7NMcoIyM7NMcoIyM7NMcoIyM7NMcoIyM7NMcoIyM7NMajNBSaqU9Iqk1yUtkvSTpLxW0suS3pX0mKRtuz5cMzPrKQo5g1oHjImIbwF1wHhJRwC3AHdGxBDgM+CirgvTzMx6mjYTVOSsTlYrkiWAMcATSflDwOldEqGZmfVIBV2DktRLUgOwHJgJ/BX4PCLWJ5s0AQO28N6LJc2VNHfFihVpxGxWdtxOzDZXUIKKiA0RUQfUAIcBB+bbbAvvnRwR9RFRX1VV1fFIzcqY24nZ5to1ii8iPgdmA0cAu0jqnbxUA3ySbmhmZtaTFTKKr0rSLsnz7YHjgcXALOCsZLMJwJNdFaSZmfU8vdvehGrgIUm9yCW0xyNihqQ3gUcl/RvwGvBAF8ZpZmY9TJsJKiIWACPylL9P7nqUmZlZ6jyThJmZZZITlJmZZZITlJmZZZITlJmZZVLZJqhB1dVISmUxM7PuV8gw85L04bJlNO1Vk0pdNZ80pVKPmZkVrmzPoMzMrLQ5QZmZWSY5QZmZWSY5QZmZWSY5QZmZWSY5QZmZWSY5QZmZWSY5QZmZWSY5QZmZWSY5QZmZWSY5QZmZWSa1maAk7S1plqTFkhZJ+kFS3k/STEnvJo+7dn24ZmbWUxRyBrUeuDIiDgSOACZKGgZcCzwXEUOA55J1MzOzVLSZoCJiaUTMT55/CSwGBgCnAQ8lmz0EnN5VQZqZWc/TrmtQkgYDI4CXgT0jYinkkhiwxxbec7GkuZLmrlixonPRmpUptxOzzRWcoCT1AX4HTIqILwp9X0RMjoj6iKivqqrqSIxmZc/txGxzBSUoSRXkktPDEfHvSfGnkqqT16uB5V0TopmZ9USFjOIT8ACwOCLuaPXSU8CE5PkE4Mn0w7PusB20edv7QpZB1dXFPhQzKyOF3PJ9FHA+8IakhqTseuBm4HFJFwEfAmd3TYjW1dYBTXvVdLqemk+aOh+MmVmizQQVEXMAbeHlsemGk03qVZHKf77qvW1q/4mrV0Uq9ZiZZVUhZ1A9Xmz4msNveLrT9bz8r+NTqae5LjOzcuapjszMLJOcoMzMLJOcoMzMLJOcoMzMLJOcoMzMLJOcoMzMLJOcoMzMLJOcoMzMLJOcoMzMLJPKdiaJtKYnMjOz4ijbBJXW9ETgaYXMzIrBXXxmZpZJTlBmZpZJTlBmZpZJZXsNqtylOQjE95ayrBlUXc2Hy5Z1up7tt+nFV99sSCEiGNi/P0uWLk2lLiuME1SJ8iAQK2cfLluW2l2e06inuS7rXm128Ul6UNJySQtblfWTNFPSu8njrl0bppmZ9TSFXIOaAmz6Ffta4LmIGAI8l6xbD7cdICmVZVB1dbEPx8yKrM0uvoj4k6TBmxSfBoxOnj8EzAauSTEuK0HrwN0pZpaajo7i2zMilgIkj3tsaUNJF0uaK2nuihUrOrg7s/JWDu1kUHV1amfQZtANgyQiYjIwGaC+vj66en9mpagc2klaAxvAZ9CW09EzqE8lVQMkj8vTC8nMzKzjCeopYELyfALwZDrhmJmZ5RQyzHwq8BfgAElNki4CbgZOkPQucEKybmZmlppCRvH9yxZeGptyLGZmZi0yNRefRwGZmVmzTE115FFAZmbWLFMJyoojrYlnPemsmaXJCcpSm3jWk86aWZoydQ3KzMysmROUmZllkhOUmZllkhOUmZllkhOUZZLvLdU9/NtDyzKP4rNM8r2luod/e2hZ5gRlqUnr91TNdZlZz+YEZalJ6/dU4N9UmZmvQZmZWUb5DMoyKc3uwm16VaRyEX9g//4sWbo0hYjKU6pdvL239fRbBRhUXc2Hy5alUlcWP99OUJZJaXcXpjEQwIMAti7tv5mn32pbuQ9ycRefmZllUqbOoNLsIjAzs9KWqQTlUWBmZtasUwlK0njgZ0Av4FcRcXMqUZmlqBzvd5XmxXErTFqDbQC26V3BN+u/TqWuctbhBCWpF3APcALQBLwq6amIeDOt4MzSUI73u0rr4ri71Av3jQfudLvODJI4DHgvIt6PiH8AjwKnpROWmZn1dIqIjr1ROgsYHxH/I1k/Hzg8Ii7bZLuLgYuT1QOAtzsebovdgZUp1JMFPpZs6uixrIyIdp9qdVE7Af9NsqqnH0tB7aQz16DydcZulu0iYjIwuRP72XzH0tyIqE+zzmLxsWRTdx9LV7QT8N8kq3wshelMF18TsHer9Rrgk86FY2ZmltOZBPUqMERSraRtgXOBp9IJy8zMeroOd/FFxHpJlwHPkBtm/mBELEotsq1LvSukiHws2VQux1IuxwE+lqzqsmPp8CAJMzOzruS5+MzMLJOcoMzMLJMyn6Ak7S1plqTFkhZJ+kFS3k/STEnvJo+7FjvWtkiqlPSKpNeTY/lJUl4r6eXkWB5LBp1knqRekl6TNCNZL8njAJDUKOkNSQ2S5iZlJfMZczvJtnJpK93dTjKfoID1wJURcSBwBDBR0jDgWuC5iBgCPJesZ906YExEfAuoA8ZLOgK4BbgzOZbPgIuKGGN7/ABY3Gq9VI+j2XERUdfqNx2l9BlzO8m2cmor3ddOIqKkFuBJcvP/vQ1UJ2XVwNvFjq2dx7EDMB84nNyvsHsn5UcCzxQ7vgLir0k+jGOAGeR+uF1yx9HqeBqB3TcpK9nPmNtJdpZyaivd3U5K4QyqhaTBwAjgZWDPiFgKkDzuUbzICpec6jcAy4GZwF+BzyNifbJJEzCgWPG1w13A1cA3yfpulOZxNAvgj5LmJdMOQel+xgbjdpIl5dRWurWdZOp+UFsjqQ/wO2BSRHyR1rT33S0iNgB1knYBpgEH5tuse6NqH0knA8sjYp6k0c3FeTbN9HFsYlREfCJpD2CmpLeKHVBHuJ1kSxm2lW5tJyWRoCRVkGt0D0fEvyfFn0qqjoilkqrJfdMqGRHxuaTZ5K4X7CKpd/KNqhSmjBoFnCrpRKAS2Inct8RSO44WEfFJ8rhc0jRys/WX1GfM7SSTyqqtdHc7yXwXn3JfAR8AFkfEHa1eegqYkDyfQK7PPdMkVSXfCJG0PXA8uQuns4Czks0yfywRcV1E1ETEYHJTXD0fEedRYsfRTNKOkvo2PwfGAQspoc+Y20k2lVNbKUo7KfZFtwIuyh1N7vR3AdCQLCeS68d9Dng3eexX7FgLOJbhwGvJsSwEbkjK9wFeAd4DfgtsV+xY23FMo4EZpXwcSdyvJ8si4EdJecl8xtxOsr+UelspRjvxVEdmZpZJme/iMzOznskJyszMMskJyszMMskJyszMMskJyszMMskJyszMMskJyszMMskJqsRJmp5M3LioefJGSRdJekfSbEm/lHR3Ul4l6XeSXk2WUcWN3qx7uJ2UJv9Qt8RJ6hcRf0umhHkV+C/Ai8BI4EvgeeD1iLhM0iPAvRExR9JAclP855uE06ysuJ2UppKYLNa26gpJZyTP9wbOB/5vRPwNQNJvgf2T148HhrWa4XonSX0j4svuDNisCNxOSpATVAlLpu8/HjgyItYksz6/Tf5bE0CuS/fIiPiqeyI0Kz63k9Lla1ClbWfgs6TRDSV3S4IdgG9L2lVSb+DMVtv/EbiseUVSXbdGa1YcbiclygmqtD0N9Ja0ALgReAn4GLiJ3N1UnwXeBP6ebH8FUC9pgaQ3gUu6P2Szbud2UqI8SKIMSeoTEauTb4bTgAcjYlqx4zLLEreT7PMZVHn6saQGcvfS+QCYXuR4zLLI7STjfAZlZmaZ5DMoMzPLJCcoMzPLJCcoMzPLJCcoMzPLJCcoMzPLpP8PlTlGZbaTvVAAAAAASUVORK5CYII=\n",
                        "text/plain": "<Figure size 432x216 with 2 Axes>"
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": "bins = np.linspace(df.age.min(), df.age.max(), 10)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'age', bins=bins, ec=\"k\")\n\ng.axes[-1].legend()\nplt.show()"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "# Pre-processing:  Feature selection/extraction"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "### Lets look at the day of the week people get the loan "
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "outputs": [
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": "<Figure size 432x216 with 2 Axes>"
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": "df['dayofweek'] = df['effective_date'].dt.dayofweek\nbins = np.linspace(df.dayofweek.min(), df.dayofweek.max(), 10)\ng = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\ng.map(plt.hist, 'dayofweek', bins=bins, ec=\"k\")\ng.axes[-1].legend()\nplt.show()"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "We see that people who get the loan at the end of the week dont pay it off, so lets use Feature binarization to set a threshold values less then day 4 "
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 0.1</th>\n      <th>loan_status</th>\n      <th>Principal</th>\n      <th>terms</th>\n      <th>effective_date</th>\n      <th>due_date</th>\n      <th>age</th>\n      <th>education</th>\n      <th>Gender</th>\n      <th>dayofweek</th>\n      <th>weekend</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>2016-09-08</td>\n      <td>2016-10-07</td>\n      <td>45</td>\n      <td>High School or Below</td>\n      <td>male</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>2016-09-08</td>\n      <td>2016-10-07</td>\n      <td>33</td>\n      <td>Bechalor</td>\n      <td>female</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>15</td>\n      <td>2016-09-08</td>\n      <td>2016-09-22</td>\n      <td>27</td>\n      <td>college</td>\n      <td>male</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>2016-09-09</td>\n      <td>2016-10-08</td>\n      <td>28</td>\n      <td>college</td>\n      <td>female</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>6</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>2016-09-09</td>\n      <td>2016-10-08</td>\n      <td>29</td>\n      <td>college</td>\n      <td>male</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   Unnamed: 0  Unnamed: 0.1 loan_status  Principal  terms effective_date  \\\n0           0             0     PAIDOFF       1000     30     2016-09-08   \n1           2             2     PAIDOFF       1000     30     2016-09-08   \n2           3             3     PAIDOFF       1000     15     2016-09-08   \n3           4             4     PAIDOFF       1000     30     2016-09-09   \n4           6             6     PAIDOFF       1000     30     2016-09-09   \n\n    due_date  age             education  Gender  dayofweek  weekend  \n0 2016-10-07   45  High School or Below    male          3        0  \n1 2016-10-07   33              Bechalor  female          3        0  \n2 2016-09-22   27               college    male          3        0  \n3 2016-10-08   28               college  female          4        1  \n4 2016-10-08   29               college    male          4        1  "
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df['weekend'] = df['dayofweek'].apply(lambda x: 1 if (x>3)  else 0)\ndf.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "## Convert Categorical features to numerical values"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "Lets look at gender:"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "Gender  loan_status\nfemale  PAIDOFF        0.865385\n        COLLECTION     0.134615\nmale    PAIDOFF        0.731293\n        COLLECTION     0.268707\nName: loan_status, dtype: float64"
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df.groupby(['Gender'])['loan_status'].value_counts(normalize=True)"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "86 % of female pay there loans while only 73 % of males pay there loan\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "Lets convert male to 0 and female to 1:\n"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 0.1</th>\n      <th>loan_status</th>\n      <th>Principal</th>\n      <th>terms</th>\n      <th>effective_date</th>\n      <th>due_date</th>\n      <th>age</th>\n      <th>education</th>\n      <th>Gender</th>\n      <th>dayofweek</th>\n      <th>weekend</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>2016-09-08</td>\n      <td>2016-10-07</td>\n      <td>45</td>\n      <td>High School or Below</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>2016-09-08</td>\n      <td>2016-10-07</td>\n      <td>33</td>\n      <td>Bechalor</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>15</td>\n      <td>2016-09-08</td>\n      <td>2016-09-22</td>\n      <td>27</td>\n      <td>college</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>2016-09-09</td>\n      <td>2016-10-08</td>\n      <td>28</td>\n      <td>college</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>6</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>2016-09-09</td>\n      <td>2016-10-08</td>\n      <td>29</td>\n      <td>college</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   Unnamed: 0  Unnamed: 0.1 loan_status  Principal  terms effective_date  \\\n0           0             0     PAIDOFF       1000     30     2016-09-08   \n1           2             2     PAIDOFF       1000     30     2016-09-08   \n2           3             3     PAIDOFF       1000     15     2016-09-08   \n3           4             4     PAIDOFF       1000     30     2016-09-09   \n4           6             6     PAIDOFF       1000     30     2016-09-09   \n\n    due_date  age             education  Gender  dayofweek  weekend  \n0 2016-10-07   45  High School or Below       0          3        0  \n1 2016-10-07   33              Bechalor       1          3        0  \n2 2016-09-22   27               college       0          3        0  \n3 2016-10-08   28               college       1          4        1  \n4 2016-10-08   29               college       0          4        1  "
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\ndf.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "## One Hot Encoding  \n#### How about education?"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "education             loan_status\nBechalor              PAIDOFF        0.750000\n                      COLLECTION     0.250000\nHigh School or Below  PAIDOFF        0.741722\n                      COLLECTION     0.258278\nMaster or Above       COLLECTION     0.500000\n                      PAIDOFF        0.500000\ncollege               PAIDOFF        0.765101\n                      COLLECTION     0.234899\nName: loan_status, dtype: float64"
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df.groupby(['education'])['loan_status'].value_counts(normalize=True)"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "#### Feature befor One Hot Encoding"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Principal</th>\n      <th>terms</th>\n      <th>age</th>\n      <th>Gender</th>\n      <th>education</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>45</td>\n      <td>0</td>\n      <td>High School or Below</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>33</td>\n      <td>1</td>\n      <td>Bechalor</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000</td>\n      <td>15</td>\n      <td>27</td>\n      <td>0</td>\n      <td>college</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>28</td>\n      <td>1</td>\n      <td>college</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>29</td>\n      <td>0</td>\n      <td>college</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   Principal  terms  age  Gender             education\n0       1000     30   45       0  High School or Below\n1       1000     30   33       1              Bechalor\n2       1000     15   27       0               college\n3       1000     30   28       1               college\n4       1000     30   29       0               college"
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df[['Principal','terms','age','Gender','education']].head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "#### Use one hot encoding technique to conver categorical varables to binary variables and append them to the feature Data Frame "
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Principal</th>\n      <th>terms</th>\n      <th>age</th>\n      <th>Gender</th>\n      <th>weekend</th>\n      <th>Bechalor</th>\n      <th>High School or Below</th>\n      <th>college</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>45</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>33</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000</td>\n      <td>15</td>\n      <td>27</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>28</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>29</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   Principal  terms  age  Gender  weekend  Bechalor  High School or Below  \\\n0       1000     30   45       0        0         0                     1   \n1       1000     30   33       1        0         1                     0   \n2       1000     15   27       0        0         0                     0   \n3       1000     30   28       1        1         0                     0   \n4       1000     30   29       0        1         0                     0   \n\n   college  \n0        0  \n1        0  \n2        1  \n3        1  \n4        1  "
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "Feature = df[['Principal','terms','age','Gender','weekend']]\nFeature = pd.concat([Feature,pd.get_dummies(df['education'])], axis=1)\nFeature.drop(['Master or Above'], axis = 1,inplace=True)\nFeature.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "### Feature selection"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "Lets defind feature sets, X:"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Principal</th>\n      <th>terms</th>\n      <th>age</th>\n      <th>Gender</th>\n      <th>weekend</th>\n      <th>Bechalor</th>\n      <th>High School or Below</th>\n      <th>college</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>45</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>33</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000</td>\n      <td>15</td>\n      <td>27</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>28</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>29</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   Principal  terms  age  Gender  weekend  Bechalor  High School or Below  \\\n0       1000     30   45       0        0         0                     1   \n1       1000     30   33       1        0         1                     0   \n2       1000     15   27       0        0         0                     0   \n3       1000     30   28       1        1         0                     0   \n4       1000     30   29       0        1         0                     0   \n\n   college  \n0        0  \n1        0  \n2        1  \n3        1  \n4        1  "
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "X = Feature\nX[0:5]"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "What are our lables?"
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "array(['PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF'],\n      dtype=object)"
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "y = df['loan_status'].values\ny[0:5]"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "## Normalize Data "
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "Data Standardization give data zero mean and unit variance (technically should be done after train test split )"
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/ipykernel/__main__.py:1: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n  if __name__ == '__main__':\n"
                },
                {
                    "data": {
                        "text/plain": "array([[ 0.51578458,  0.92071769,  2.33152555, -0.42056004, -1.20577805,\n        -0.38170062,  1.13639374, -0.86968108],\n       [ 0.51578458,  0.92071769,  0.34170148,  2.37778177, -1.20577805,\n         2.61985426, -0.87997669, -0.86968108],\n       [ 0.51578458, -0.95911111, -0.65321055, -0.42056004, -1.20577805,\n        -0.38170062, -0.87997669,  1.14984679],\n       [ 0.51578458,  0.92071769, -0.48739188,  2.37778177,  0.82934003,\n        -0.38170062, -0.87997669,  1.14984679],\n       [ 0.51578458,  0.92071769, -0.3215732 , -0.42056004,  0.82934003,\n        -0.38170062, -0.87997669,  1.14984679]])"
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "X= preprocessing.StandardScaler().fit(X).transform(X)\nX[0:5]"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "# Classification "
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "Now, it is your turn, use the training set to build an accurate model. Then use the test set to report the accuracy of the model\nYou should use the following algorithm:\n- K Nearest Neighbor(KNN)\n- Decision Tree\n- Support Vector Machine\n- Logistic Regression\n\n\n\n__ Notice:__ \n- You can go above and change the pre-processing, feature selection, feature-extraction, and so on, to make a better model.\n- You should use either scikit-learn, Scipy or Numpy libraries for developing the classification algorithms.\n- You should include the code of the algorithm in the following cells."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# K Nearest Neighbor(KNN)\nNotice: You should find the best k to build the model with the best accuracy.  \n**warning:** You should not use the __loan_test.csv__ for finding the best k, however, you can split your train_loan.csv into train and test to find the best __k__."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Train Test Spilt"
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "X_Train shape:(276, 8)\ny_train shape:(276,)\nX_test shape:(70, 8)\ny_test shape:(70,)\n"
                }
            ],
            "source": "from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2,random_state = 4)\nprint(\"X_Train shape:{}\\ny_train shape:{}\\nX_test shape:{}\\ny_test shape:{}\".format(X_train.shape,y_train.shape,X_test.shape,y_test.shape))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Applying KNN for values from 1 to 10"
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics"
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Accuracy with K value = 1 is 67.14285714285714 %\nAccuracy with K value = 2 is 65.71428571428571 %\nAccuracy with K value = 3 is 71.42857142857143 %\nAccuracy with K value = 4 is 68.57142857142857 %\nAccuracy with K value = 5 is 75.71428571428571 %\nAccuracy with K value = 6 is 71.42857142857143 %\nAccuracy with K value = 7 is 78.57142857142857 %\nAccuracy with K value = 8 is 75.71428571428571 %\nAccuracy with K value = 9 is 75.71428571428571 %\n\nThe KNN algorithm in this case has best accuracy for K value = 7\n"
                }
            ],
            "source": "K_max = 10\nmean_acc = np.zeros((K_max-1))\nstd_acc = np.zeros((K_max-1))\n\nfor n in range(1,K_max):\n    \n    #Train Model and Predict  \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n    y_pred_knn = neigh.predict(X_test)\n    mean_acc[n-1] = metrics.accuracy_score(y_test, y_pred_knn)\n    std_acc[n-1]=np.std(y_pred_knn==y_test)/np.sqrt(y_pred_knn.shape[0])\n    print('Accuracy with K value = {} is {} %'.format(n,mean_acc[n-1]*100))\n    \nprint('\\nThe KNN algorithm in this case has best accuracy for K value = {}'.format(mean_acc.argmax()+1))"
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": "<Figure size 432x288 with 1 Axes>"
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": "plt.plot(list(np.arange(1,10)),mean_acc,color='blue')\nplt.xlabel('K value')\nplt.ylabel('Accuracy (in %)')\nplt.show()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Decision Tree"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Applying Decision Tree for the problem"
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.tree import DecisionTreeClassifier"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Training the dataset with different max_depth values"
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "The accuracy for max depth = 2 is 74.03846153846155 %\nThe accuracy for max depth = 3 is 74.03846153846155 %\nThe accuracy for max depth = 4 is 74.03846153846155 %\nThe accuracy for max depth = 5 is 74.03846153846155 %\nThe accuracy for max depth = 6 is 74.03846153846155 %\nThe accuracy for max depth = 7 is 75.0 %\nThe accuracy for max depth = 8 is 71.15384615384616 %\nThe accuracy for max depth = 9 is 70.1923076923077 %\n\nThe Decision Tree Classifier in this case has the best accuracy for max_depth = 7\n"
                }
            ],
            "source": "X_trainnew, X_testnew, y_trainnew, y_testnew = train_test_split(X,y,test_size = 0.3,random_state = 4)\ndmax = 10\ndectree_acc = np.zeros((dmax-1))\nfor n in range(2,dmax):\n    tree_obj = DecisionTreeClassifier(criterion = 'entropy',max_depth = n)\n    tree_obj.fit(X_trainnew,y_trainnew)\n    y_pred_dec = tree_obj.predict(X_testnew)\n    dectree_acc[n-2] = metrics.accuracy_score(y_testnew,y_pred_dec)\n    print('The accuracy for max depth = {} is {} %'.format(n,dectree_acc[n-2]*100))\n    \nprint('\\nThe Decision Tree Classifier in this case has the best accuracy for max_depth = {}'.format(dectree_acc.argmax()+2))"
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": "<Figure size 432x288 with 1 Axes>"
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": "plt.plot(list(np.arange(2,11)),dectree_acc,color='red')\nplt.xlabel('Max_depth')\nplt.ylabel('Accuracy (in %)')\nplt.show()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Support Vector Machine"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Training the model with SVM"
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.svm import SVC"
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [],
            "source": "kernels = ['linear','poly','rbf','sigmoid']"
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "For linear Kernel Function Type:\n\n\t\t\tClassification Report\n\t\t------------------------------------\n\t\t\n              precision    recall  f1-score   support\n\n  COLLECTION       0.00      0.00      0.00        15\n     PAIDOFF       0.79      1.00      0.88        55\n\n   micro avg       0.79      0.79      0.79        70\n   macro avg       0.39      0.50      0.44        70\nweighted avg       0.62      0.79      0.69        70\n\n\t\t\tConfusion Matrix\n\t\t-----------------------------\n\t\t\n[[ 0 15]\n [ 0 55]]\n\nAccuracy with linear Kernel type = 78.57142857142857 %\n\n\n\n\nFor poly Kernel Function Type:\n\n\t\t\tClassification Report\n\t\t------------------------------------\n\t\t\n              precision    recall  f1-score   support\n\n  COLLECTION       0.33      0.07      0.11        15\n     PAIDOFF       0.79      0.96      0.87        55\n\n   micro avg       0.77      0.77      0.77        70\n   macro avg       0.56      0.52      0.49        70\nweighted avg       0.69      0.77      0.71        70\n\n\t\t\tConfusion Matrix\n\t\t-----------------------------\n\t\t\n[[ 1 14]\n [ 2 53]]\n\nAccuracy with poly Kernel type = 77.14285714285715 %\n\n\n\n\nFor rbf Kernel Function Type:\n\n\t\t\tClassification Report\n\t\t------------------------------------\n\t\t\n              precision    recall  f1-score   support\n\n  COLLECTION       0.36      0.27      0.31        15\n     PAIDOFF       0.81      0.87      0.84        55\n\n   micro avg       0.74      0.74      0.74        70\n   macro avg       0.59      0.57      0.57        70\nweighted avg       0.72      0.74      0.73        70\n\n\t\t\tConfusion Matrix\n\t\t-----------------------------\n\t\t\n[[ 4 11]\n [ 7 48]]\n\nAccuracy with rbf Kernel type = 74.28571428571429 %\n\n\n\n\nFor sigmoid Kernel Function Type:\n\n\t\t\tClassification Report\n\t\t------------------------------------\n\t\t\n              precision    recall  f1-score   support\n\n  COLLECTION       0.20      0.07      0.10        15\n     PAIDOFF       0.78      0.93      0.85        55\n\n   micro avg       0.74      0.74      0.74        70\n   macro avg       0.49      0.50      0.48        70\nweighted avg       0.66      0.74      0.69        70\n\n\t\t\tConfusion Matrix\n\t\t-----------------------------\n\t\t\n[[ 1 14]\n [ 4 51]]\n\nAccuracy with sigmoid Kernel type = 74.28571428571429 %\n\n\n\n\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n"
                }
            ],
            "source": "#model with 80% training data size\nsvm_acc = np.zeros((4))\ni=0\nfor k_name in kernels:\n    svc = SVC(kernel = k_name)\n    svc.fit(X_train,y_train)\n    y_pred_svm = svc.predict(X_test)\n    svm_acc[i] = metrics.accuracy_score(y_test,y_pred_svm)\n    print('For {} Kernel Function Type:\\n'.format(k_name))\n    print('\\t\\t\\tClassification Report\\n\\t\\t------------------------------------\\n\\t\\t')\n    print(metrics.classification_report(y_test,y_pred_svm))\n    print('\\t\\t\\tConfusion Matrix\\n\\t\\t-----------------------------\\n\\t\\t')\n    print(metrics.confusion_matrix(y_test,y_pred_svm))\n    print('\\nAccuracy with {} Kernel type = {} %'.format(k_name,svm_acc[i]*100))\n    i = i+1\n    print('\\n\\n\\n')"
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "For linear Kernel Function Type:\n\n\t\t\tClassification Report\n\t\t------------------------------------\n\t\t\n              precision    recall  f1-score   support\n\n  COLLECTION       0.00      0.00      0.00        27\n     PAIDOFF       0.74      1.00      0.85        77\n\n   micro avg       0.74      0.74      0.74       104\n   macro avg       0.37      0.50      0.43       104\nweighted avg       0.55      0.74      0.63       104\n\n\t\t\tConfusion Matrix\n\t\t-----------------------------\n\t\t\n[[ 0 27]\n [ 0 77]]\n\nAccuracy with linear Kernel type = 74.03846153846155 %\n\n\n\n\nFor poly Kernel Function Type:\n\n\t\t\tClassification Report\n\t\t------------------------------------\n\t\t\n              precision    recall  f1-score   support\n\n  COLLECTION       0.67      0.07      0.13        27\n     PAIDOFF       0.75      0.99      0.85        77\n\n   micro avg       0.75      0.75      0.75       104\n   macro avg       0.71      0.53      0.49       104\nweighted avg       0.73      0.75      0.67       104\n\n\t\t\tConfusion Matrix\n\t\t-----------------------------\n\t\t\n[[ 2 25]\n [ 1 76]]\n\nAccuracy with poly Kernel type = 75.0 %\n\n\n\n\nFor rbf Kernel Function Type:\n\n\t\t\tClassification Report\n\t\t------------------------------------\n\t\t\n              precision    recall  f1-score   support\n\n  COLLECTION       1.00      0.04      0.07        27\n     PAIDOFF       0.75      1.00      0.86        77\n\n   micro avg       0.75      0.75      0.75       104\n   macro avg       0.87      0.52      0.46       104\nweighted avg       0.81      0.75      0.65       104\n\n\t\t\tConfusion Matrix\n\t\t-----------------------------\n\t\t\n[[ 1 26]\n [ 0 77]]\n\nAccuracy with rbf Kernel type = 75.0 %\n\n\n\n\nFor sigmoid Kernel Function Type:\n\n\t\t\tClassification Report\n\t\t------------------------------------\n\t\t\n              precision    recall  f1-score   support\n\n  COLLECTION       0.00      0.00      0.00        27\n     PAIDOFF       0.73      0.96      0.83        77\n\n   micro avg       0.71      0.71      0.71       104\n   macro avg       0.37      0.48      0.42       104\nweighted avg       0.54      0.71      0.62       104\n\n\t\t\tConfusion Matrix\n\t\t-----------------------------\n\t\t\n[[ 0 27]\n [ 3 74]]\n\nAccuracy with sigmoid Kernel type = 71.15384615384616 %\n\n\n\n\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n"
                }
            ],
            "source": "#model with 70% training data size\nsvm_acc = np.zeros((4))\ni=0\nfor k_name in kernels:\n    svc = SVC(kernel = k_name)\n    svc.fit(X_trainnew,y_trainnew)\n    y_pred_svm2 = svc.predict(X_testnew)\n    svm_acc[i] = metrics.accuracy_score(y_testnew,y_pred_svm2)\n    print('For {} Kernel Function Type:\\n'.format(k_name))\n    print('\\t\\t\\tClassification Report\\n\\t\\t------------------------------------\\n\\t\\t')\n    print(metrics.classification_report(y_testnew,y_pred_svm2))\n    print('\\t\\t\\tConfusion Matrix\\n\\t\\t-----------------------------\\n\\t\\t')\n    print(metrics.confusion_matrix(y_testnew,y_pred_svm2))\n    print('\\nAccuracy with {} Kernel type = {} %'.format(k_name,svm_acc[i]*100))\n    i = i+1\n    print('\\n\\n\\n')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Logistic Regression"
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.linear_model import LogisticRegression\nsolvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\nreg_par = [1,0.1,0.01,0.5,0.05,0.02,0.2]"
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "For newton-cg solver and C value = 1, \naccuracy is 72.85714285714285 %\nPredicted Probabilities ar:\n[[0.51845695 0.48154305]\n [0.38663462 0.61336538]\n [0.02326666 0.97673334]\n [0.03501069 0.96498931]\n [0.02344794 0.97655206]\n [0.02732948 0.97267052]\n [0.45665709 0.54334291]\n [0.41607168 0.58392832]\n [0.03501069 0.96498931]\n [0.45827831 0.54172169]\n [0.03232611 0.96767389]\n [0.45333433 0.54666567]\n [0.0166259  0.9833741 ]\n [0.03995489 0.96004511]\n [0.28127177 0.71872823]\n [0.01012538 0.98987462]\n [0.59966921 0.40033079]\n [0.01876197 0.98123803]\n [0.47386107 0.52613893]\n [0.0268046  0.9731954 ]\n [0.26512923 0.73487077]\n [0.44312578 0.55687422]\n [0.55946084 0.44053916]\n [0.40446269 0.59553731]\n [0.21863961 0.78136039]\n [0.53902491 0.46097509]\n [0.54926365 0.45073635]\n [0.17231646 0.82768354]\n [0.48416207 0.51583793]\n [0.00700316 0.99299684]\n [0.3589193  0.6410807 ]\n [0.32507846 0.67492154]\n [0.42644563 0.57355437]\n [0.40285132 0.59714868]\n [0.22287069 0.77712931]\n [0.32187452 0.67812548]\n [0.47386107 0.52613893]\n [0.0146612  0.9853388 ]\n [0.34647417 0.65352583]\n [0.34574165 0.65425835]\n [0.49447655 0.50552345]\n [0.02790268 0.97209732]\n [0.33392348 0.66607652]\n [0.53902491 0.46097509]\n [0.01953719 0.98046281]\n [0.50565995 0.49434005]\n [0.36847153 0.63152847]\n [0.45333433 0.54666567]\n [0.31293169 0.68706831]\n [0.3211919  0.6788081 ]\n [0.01380109 0.98619891]\n [0.40018979 0.59981021]\n [0.03191561 0.96808439]\n [0.42286038 0.57713962]\n [0.03630687 0.96369313]\n [0.00896654 0.99103346]\n [0.02473313 0.97526687]\n [0.22690538 0.77309462]\n [0.3589193  0.6410807 ]\n [0.03546623 0.96453377]\n [0.1562917  0.8437083 ]\n [0.0286689  0.9713311 ]\n [0.32187452 0.67812548]\n [0.60953671 0.39046329]\n [0.02904441 0.97095559]\n [0.44312578 0.55687422]\n [0.0286689  0.9713311 ]\n [0.20245036 0.79754964]\n [0.32480623 0.67519377]\n [0.02904441 0.97095559]]\n\n\n\nFor newton-cg solver and C value = 0.1, \naccuracy is 77.14285714285715 %\nPredicted Probabilities ar:\n[[0.47119047 0.52880953]\n [0.3571984  0.6428016 ]\n [0.06428917 0.93571083]\n [0.08720115 0.91279885]\n [0.06491815 0.93508185]\n [0.07241091 0.92758909]\n [0.42387376 0.57612624]\n [0.39303449 0.60696551]\n [0.08720115 0.91279885]\n [0.42920173 0.57079827]\n [0.08225165 0.91774835]\n [0.42390673 0.57609327]\n [0.04156262 0.95843738]\n [0.09511936 0.90488064]\n [0.2907508  0.7092492 ]\n [0.03400487 0.96599513]\n [0.53494321 0.46505679]\n [0.05533709 0.94466291]\n [0.43956827 0.56043173]\n [0.0709703  0.9290297 ]\n [0.27515661 0.72484339]\n [0.41613089 0.58386911]\n [0.50307936 0.49692064]\n [0.37990838 0.62009162]\n [0.23271505 0.76728495]\n [0.48712181 0.51287819]\n [0.49509934 0.50490066]\n [0.18648934 0.81351066]\n [0.44744644 0.55255356]\n [0.02590867 0.97409133]\n [0.35335653 0.64664347]\n [0.32187484 0.67812516]\n [0.38701874 0.61298126]\n [0.38547803 0.61452197]\n [0.22698691 0.77301309]\n [0.32475577 0.67524423]\n [0.43956827 0.56043173]\n [0.04617662 0.95382338]\n [0.335935   0.664065  ]\n [0.33943649 0.66056351]\n [0.45535109 0.54464891]\n [0.073104   0.926896  ]\n [0.33176453 0.66823547]\n [0.48712181 0.51287819]\n [0.05702963 0.94297037]\n [0.46130939 0.53869061]\n [0.36068399 0.63931601]\n [0.42390673 0.57609327]\n [0.31779539 0.68220461]\n [0.32495425 0.67504575]\n [0.04253995 0.95746005]\n [0.38322923 0.61677077]\n [0.07575042 0.92424958]\n [0.40070734 0.59929266]\n [0.07534139 0.92465861]\n [0.02957082 0.97042918]\n [0.06687457 0.93312543]\n [0.24448982 0.75551018]\n [0.35335653 0.64664347]\n [0.0871904  0.9128096 ]\n [0.23169541 0.76830459]\n [0.07530604 0.92469396]\n [0.32475577 0.67524423]\n [0.54287493 0.45712507]\n [0.07529664 0.92470336]\n [0.41613089 0.58386911]\n [0.07530604 0.92469396]\n [0.22543744 0.77456256]\n [0.32472617 0.67527383]\n [0.07529664 0.92470336]]\n\n\n\nFor newton-cg solver and C value = 0.01, \naccuracy is 78.57142857142857 %\nPredicted Probabilities ar:\n[[0.34685108 0.65314892]\n [0.29471107 0.70528893]\n [0.17787889 0.82212111]\n [0.20143595 0.79856405]\n [0.18315053 0.81684947]\n [0.18487468 0.81512532]\n [0.33101648 0.66898352]\n [0.32066611 0.67933389]\n [0.20143595 0.79856405]\n [0.33057531 0.66942469]\n [0.19767265 0.80232735]\n [0.3334419  0.6665581 ]\n [0.13571868 0.86428132]\n [0.20539087 0.79460913]\n [0.28083128 0.71916872]\n [0.14086588 0.85913412]\n [0.36849762 0.63150238]\n [0.17097208 0.82902792]\n [0.33869881 0.66130119]\n [0.18683044 0.81316956]\n [0.27688641 0.72311359]\n [0.33082879 0.66917121]\n [0.35760174 0.64239826]\n [0.31127025 0.68872975]\n [0.24926061 0.75073939]\n [0.3522077  0.6477923 ]\n [0.35490011 0.64509989]\n [0.22560318 0.77439682]\n [0.34134237 0.65865763]\n [0.13088289 0.86911711]\n [0.30504519 0.69495481]\n [0.29369672 0.70630328]\n [0.30459932 0.69540068]\n [0.32048147 0.67951853]\n [0.24263702 0.75736298]\n [0.29514861 0.70485139]\n [0.33869881 0.66130119]\n [0.15972769 0.84027231]\n [0.29632306 0.70367694]\n [0.30314088 0.69685912]\n [0.34399583 0.65600417]\n [0.18862676 0.81137324]\n [0.29532499 0.70467501]\n [0.3522077  0.6477923 ]\n [0.1726483  0.8273517 ]\n [0.34436518 0.65563482]\n [0.30754824 0.69245176]\n [0.3334419  0.6665581 ]\n [0.29270382 0.70729618]\n [0.29290259 0.70709741]\n [0.15575891 0.84424109]\n [0.31044949 0.68955051]\n [0.17929833 0.82070167]\n [0.32563388 0.67436612]\n [0.16554344 0.83445656]\n [0.13292223 0.86707777]\n [0.18327739 0.81672261]\n [0.26524946 0.73475054]\n [0.30504519 0.69495481]\n [0.19968308 0.80031692]\n [0.26220111 0.73779889]\n [0.19212749 0.80787251]\n [0.29514861 0.70485139]\n [0.3712432  0.6287568 ]\n [0.19043631 0.80956369]\n [0.33082879 0.66917121]\n [0.19212749 0.80787251]\n [0.25371293 0.74628707]\n [0.29287935 0.70712065]\n [0.19043631 0.80956369]]\n\n\n\nFor newton-cg solver and C value = 0.5, \naccuracy is 74.28571428571429 %\nPredicted Probabilities ar:\n[[0.51119625 0.48880375]\n [0.38141342 0.61858658]\n [0.02933558 0.97066442]\n [0.04339328 0.95660672]\n [0.02953768 0.97046232]\n [0.0342383  0.9657617 ]\n [0.45149836 0.54850164]\n [0.41235804 0.58764196]\n [0.04339328 0.95660672]\n [0.45455133 0.54544867]\n [0.04019871 0.95980129]\n [0.44896031 0.55103969]\n [0.02039666 0.97960334]\n [0.04911968 0.95088032]\n [0.28288842 0.71711158]\n [0.01317561 0.98682439]\n [0.59001011 0.40998989]\n [0.02391736 0.97608264]\n [0.46877352 0.53122648]\n [0.03349965 0.96650035]\n [0.26675839 0.73324161]\n [0.43911017 0.56088983]\n [0.55092278 0.44907722]\n [0.40074772 0.59925228]\n [0.2209478  0.7790522 ]\n [0.5311088  0.4688912 ]\n [0.54103201 0.45896799]\n [0.17380858 0.82619142]\n [0.47872115 0.52127885]\n [0.00924111 0.99075889]\n [0.35862979 0.64137021]\n [0.32479567 0.67520433]\n [0.41971439 0.58028561]\n [0.40026009 0.59973991]\n [0.22285916 0.77714084]\n [0.32280222 0.67719778]\n [0.46877352 0.53122648]\n [0.01889811 0.98110189]\n [0.34484844 0.65515156]\n [0.34457703 0.65542297]\n [0.48868568 0.51131432]\n [0.03481589 0.96518411]\n [0.33386227 0.66613773]\n [0.5311088  0.4688912 ]\n [0.02486679 0.97513321]\n [0.49886656 0.50113344]\n [0.36785862 0.63214138]\n [0.44896031 0.55103969]\n [0.31414202 0.68585798]\n [0.32252665 0.67747335]\n [0.01766715 0.98233285]\n [0.39826107 0.60173893]\n [0.03909401 0.96090599]\n [0.4195605  0.5804395 ]\n [0.04325493 0.95674507]\n [0.01155382 0.98844618]\n [0.03100983 0.96899017]\n [0.22958763 0.77041237]\n [0.35862979 0.64137021]\n [0.04382092 0.95617908]\n [0.18441434 0.81558566]\n [0.03582604 0.96417396]\n [0.32280222 0.67719778]\n [0.59962647 0.40037353]\n [0.03618192 0.96381808]\n [0.43911017 0.56088983]\n [0.03582604 0.96417396]\n [0.20625091 0.79374909]\n [0.32504777 0.67495223]\n [0.03618192 0.96381808]]\n\n\n\nFor newton-cg solver and C value = 0.05, \naccuracy is 78.57142857142857 %\nPredicted Probabilities ar:\n[[0.43996154 0.56003846]\n [0.34016551 0.65983449]\n [0.09267494 0.90732506]\n [0.11917613 0.88082387]\n [0.09429798 0.90570202]\n [0.10187118 0.89812882]\n [0.40166909 0.59833091]\n [0.37676229 0.62323771]\n [0.11917613 0.88082387]\n [0.40602331 0.59397669]\n [0.11378445 0.88621555]\n [0.40299623 0.59700377]\n [0.06008155 0.93991845]\n [0.12706351 0.87293649]\n [0.29240338 0.70759662]\n [0.05500106 0.94499894]\n [0.49207021 0.50792979]\n [0.08264948 0.91735052]\n [0.41566443 0.58433557]\n [0.10072715 0.89927285]\n [0.27931315 0.72068685]\n [0.39670921 0.60329079]\n [0.46592291 0.53407709]\n [0.36345555 0.63654445]\n [0.23921326 0.76078674]\n [0.4529102  0.5470898 ]\n [0.45940964 0.54059036]\n [0.19681077 0.80318923]\n [0.4220417  0.5779583 ]\n [0.04450813 0.95549187]\n [0.34469859 0.65530141]\n [0.31767561 0.68232439]\n [0.36406624 0.63593376]\n [0.3719188  0.6280812 ]\n [0.23107089 0.76892911]\n [0.32142668 0.67857332]\n [0.41566443 0.58433557]\n [0.07135167 0.92864833]\n [0.32792291 0.67207709]\n [0.33353646 0.66646354]\n [0.42844507 0.57155493]\n [0.10312528 0.89687472]\n [0.32595387 0.67404613]\n [0.4529102  0.5470898 ]\n [0.08465773 0.91534227]\n [0.43216078 0.56783922]\n [0.35064042 0.64935958]\n [0.40299623 0.59700377]\n [0.31573919 0.68426081]\n [0.32098387 0.67901613]\n [0.06631204 0.93368796]\n [0.36698414 0.63301586]\n [0.10242767 0.89757233]\n [0.38423883 0.61576117]\n [0.09717941 0.90282059]\n [0.04846644 0.95153356]\n [0.09607908 0.90392092]\n [0.25372013 0.74627987]\n [0.34469859 0.65530141]\n [0.11859798 0.88140202]\n [0.24658842 0.75341158]\n [0.10609611 0.89390389]\n [0.32142668 0.67857332]\n [0.49861943 0.50138057]\n [0.10557381 0.89442619]\n [0.39670921 0.60329079]\n [0.10609611 0.89390389]\n [0.23665615 0.76334385]\n [0.32022408 0.67977592]\n [0.10557381 0.89442619]]\n\n\n\nFor newton-cg solver and C value = 0.02, \naccuracy is 78.57142857142857 %\nPredicted Probabilities ar:\n[[0.38769413 0.61230587]\n [0.31377004 0.68622996]\n [0.14068246 0.85931754]\n [0.16801614 0.83198386]\n [0.14470065 0.85529935]\n [0.1494628  0.8505372 ]\n [0.36279949 0.63720051]\n [0.34659354 0.65340646]\n [0.16801614 0.83198386]\n [0.36417594 0.63582406]\n [0.16312482 0.83687518]\n [0.36524132 0.63475868]\n [0.09792773 0.90207227]\n [0.17405008 0.82594992]\n [0.28818982 0.71181018]\n [0.09897755 0.90102245]\n [0.42179962 0.57820038]\n [0.1315182  0.8684818 ]\n [0.37348841 0.62651159]\n [0.15004828 0.84995172]\n [0.28049839 0.71950161]\n [0.3611469  0.6388531 ]\n [0.40463176 0.59536824]\n [0.33470273 0.66529727]\n [0.24588413 0.75411587]\n [0.3961318  0.6038682 ]\n [0.40037428 0.59962572]\n [0.21310227 0.78689773]\n [0.37764004 0.62235996]\n [0.08724732 0.91275268]\n [0.32424829 0.67575171]\n [0.30617375 0.69382625]\n [0.3292145  0.6707855 ]\n [0.34497481 0.65502519]\n [0.23757019 0.76242981]\n [0.30892951 0.69107049]\n [0.37348841 0.62651159]\n [0.11897489 0.88102511]\n [0.31147983 0.68852017]\n [0.31879502 0.68120498]\n [0.3818097  0.6181903 ]\n [0.15232004 0.84767996]\n [0.31045927 0.68954073]\n [0.3961318  0.6038682 ]\n [0.1335535  0.8664465 ]\n [0.38318181 0.61681819]\n [0.32813925 0.67186075]\n [0.36524132 0.63475868]\n [0.30516287 0.69483713]\n [0.30714897 0.69285103]\n [0.11364274 0.88635726]\n [0.33572485 0.66427515]\n [0.14562271 0.85437729]\n [0.35301878 0.64698122]\n [0.13380057 0.86619943]\n [0.09049519 0.90950481]\n [0.14558851 0.85441149]\n [0.26298593 0.73701407]\n [0.32424829 0.67575171]\n [0.1665469  0.8334531 ]\n [0.25898116 0.74101884]\n [0.15600366 0.84399634]\n [0.30892951 0.69107049]\n [0.42612301 0.57387699]\n [0.15461994 0.84538006]\n [0.3611469  0.6388531 ]\n [0.15600366 0.84399634]\n [0.24863283 0.75136717]\n [0.30668225 0.69331775]\n [0.15461994 0.84538006]]\n\n\n\nFor newton-cg solver and C value = 0.2, \naccuracy is 75.71428571428571 %\nPredicted Probabilities ar:\n[[0.49345148 0.50654852]\n [0.37016408 0.62983592]\n [0.04455752 0.95544248]\n [0.0632476  0.9367524 ]\n [0.04485316 0.95514684]\n [0.05116642 0.94883358]\n [0.43928581 0.56071419]\n [0.40388469 0.59611531]\n [0.0632476  0.9367524 ]\n [0.44410567 0.55589433]\n [0.059079   0.940921  ]\n [0.43807395 0.56192605]\n [0.02959081 0.97040919]\n [0.07033808 0.92966192]\n [0.28710184 0.71289816]\n [0.02156197 0.97843803]\n [0.56569101 0.43430899]\n [0.03725976 0.96274024]\n [0.45602375 0.54397625]\n [0.04999155 0.95000845]\n [0.27076286 0.72923714]\n [0.4291565  0.5708435 ]\n [0.52972692 0.47027308]\n [0.39146212 0.60853788]\n [0.22657112 0.77342888]\n [0.51160448 0.48839552]\n [0.5206725  0.4793275 ]\n [0.17908765 0.82091235]\n [0.46504467 0.53495533]\n [0.01569048 0.98430952]\n [0.35718001 0.64281999]\n [0.32375263 0.67624737]\n [0.4046157  0.5953843 ]\n [0.39399808 0.60600192]\n [0.2242866  0.7757134 ]\n [0.32456557 0.67543443]\n [0.45602375 0.54397625]\n [0.03021342 0.96978658]\n [0.34095622 0.65904378]\n [0.34247461 0.65752539]\n [0.47408851 0.52591149]\n [0.0517445  0.9482555 ]\n [0.33366921 0.66633079]\n [0.51160448 0.48839552]\n [0.0385844  0.9614156 ]\n [0.48217975 0.51782025]\n [0.36555962 0.63444038]\n [0.43807395 0.56192605]\n [0.31665664 0.68334336]\n [0.32477285 0.67522715]\n [0.0279239  0.9720761 ]\n [0.39257184 0.60742816]\n [0.05584411 0.94415589]\n [0.41146431 0.58853569]\n [0.05847371 0.94152629]\n [0.01873798 0.98126202]\n [0.04665314 0.95334686]\n [0.23643766 0.76356234]\n [0.35718001 0.64281999]\n [0.06353981 0.93646019]\n [0.21364342 0.78635658]\n [0.05330653 0.94669347]\n [0.32456557 0.67543443]\n [0.57458984 0.42541016]\n [0.05355544 0.94644456]\n [0.4291565  0.5708435 ]\n [0.05330653 0.94669347]\n [0.21533076 0.78466924]\n [0.3256454  0.6743546 ]\n [0.05355544 0.94644456]]\n\n\n\nFor lbfgs solver and C value = 1, \naccuracy is 72.85714285714285 %\nPredicted Probabilities ar:\n[[0.51845689 0.48154311]\n [0.38663558 0.61336442]\n [0.02326667 0.97673333]\n [0.03501101 0.96498899]\n [0.02344812 0.97655188]\n [0.0273295  0.9726705 ]\n [0.45665682 0.54334318]\n [0.41607128 0.58392872]\n [0.03501101 0.96498899]\n [0.45828046 0.54171954]\n [0.0323264  0.9676736 ]\n [0.45333621 0.54666379]\n [0.01662574 0.98337426]\n [0.03995494 0.96004506]\n [0.28127121 0.71872879]\n [0.01012531 0.98987469]\n [0.59966943 0.40033057]\n [0.01876212 0.98123788]\n [0.47386304 0.52613696]\n [0.0268046  0.9731954 ]\n [0.26512852 0.73487148]\n [0.44312762 0.55687238]\n [0.55946092 0.44053908]\n [0.40446024 0.59553976]\n [0.2186388  0.7813612 ]\n [0.53902492 0.46097508]\n [0.5492637  0.4507363 ]\n [0.17231405 0.82768595]\n [0.48416408 0.51583592]\n [0.00700314 0.99299686]\n [0.35892096 0.64107904]\n [0.32507789 0.67492211]\n [0.42644675 0.57355325]\n [0.40285298 0.59714702]\n [0.22286862 0.77713138]\n [0.32187597 0.67812403]\n [0.47386304 0.52613696]\n [0.01466131 0.98533869]\n [0.34647167 0.65352833]\n [0.34574189 0.65425811]\n [0.49447859 0.50552141]\n [0.02790268 0.97209732]\n [0.33392305 0.66607695]\n [0.53902492 0.46097508]\n [0.01953735 0.98046265]\n [0.50566079 0.49433921]\n [0.36847324 0.63152676]\n [0.45333621 0.54666379]\n [0.31293309 0.68706691]\n [0.32119346 0.67880654]\n [0.01380099 0.98619901]\n [0.40018969 0.59981031]\n [0.03191554 0.96808446]\n [0.42286214 0.57713786]\n [0.03630664 0.96369336]\n [0.00896656 0.99103344]\n [0.02473311 0.97526689]\n [0.22690462 0.77309538]\n [0.35892096 0.64107904]\n [0.03546626 0.96453374]\n [0.15628995 0.84371005]\n [0.02866914 0.97133086]\n [0.32187597 0.67812403]\n [0.60953696 0.39046304]\n [0.02904441 0.97095559]\n [0.44312762 0.55687238]\n [0.02866914 0.97133086]\n [0.20244974 0.79755026]\n [0.32480578 0.67519422]\n [0.02904441 0.97095559]]\n\n\n\nFor lbfgs solver and C value = 0.1, \naccuracy is 77.14285714285715 %\nPredicted Probabilities ar:\n[[0.4711892  0.5288108 ]\n [0.35719919 0.64280081]\n [0.06428933 0.93571067]\n [0.08720219 0.91279781]\n [0.06491859 0.93508141]\n [0.07241125 0.92758875]\n [0.42387165 0.57612835]\n [0.39303186 0.60696814]\n [0.08720219 0.91279781]\n [0.4292027  0.5707973 ]\n [0.08225255 0.91774745]\n [0.42390663 0.57609337]\n [0.04156338 0.95843662]\n [0.09511994 0.90488006]\n [0.2907476  0.7092524 ]\n [0.03400382 0.96599618]\n [0.53494312 0.46505688]\n [0.05533751 0.94466249]\n [0.43956847 0.56043153]\n [0.07097035 0.92902965]\n [0.2751549  0.7248451 ]\n [0.41613065 0.58386935]\n [0.50307867 0.49692133]\n [0.37990651 0.62009349]\n [0.2327143  0.7672857 ]\n [0.48712083 0.51287917]\n [0.49509851 0.50490149]\n [0.18648674 0.81351326]\n [0.44744679 0.55255321]\n [0.02590861 0.97409139]\n [0.35335608 0.64664392]\n [0.32187387 0.67812613]\n [0.38702011 0.61297989]\n [0.38547724 0.61452276]\n [0.22697973 0.77302027]\n [0.32475482 0.67524518]\n [0.43956847 0.56043153]\n [0.0461769  0.9538231 ]\n [0.33593243 0.66406757]\n [0.33942671 0.66057329]\n [0.45535158 0.54464842]\n [0.07310409 0.92689591]\n [0.33176187 0.66823813]\n [0.48712083 0.51287917]\n [0.05703009 0.94296991]\n [0.4613009  0.5386991 ]\n [0.36068368 0.63931632]\n [0.42390663 0.57609337]\n [0.31779432 0.68220568]\n [0.32495376 0.67504624]\n [0.04253858 0.95746142]\n [0.38322788 0.61677212]\n [0.07575119 0.92424881]\n [0.40070682 0.59929318]\n [0.07534282 0.92465718]\n [0.02957085 0.97042915]\n [0.06687454 0.93312546]\n [0.2444877  0.7555123 ]\n [0.35335608 0.64664392]\n [0.08719079 0.91280921]\n [0.23169279 0.76830721]\n [0.07530675 0.92469325]\n [0.32475482 0.67524518]\n [0.54287499 0.45712501]\n [0.07529678 0.92470322]\n [0.41613065 0.58386935]\n [0.07530675 0.92469325]\n [0.22543577 0.77456423]\n [0.32472341 0.67527659]\n [0.07529678 0.92470322]]\n\n\n\nFor lbfgs solver and C value = 0.01, \naccuracy is 78.57142857142857 %\nPredicted Probabilities ar:\n[[0.34684947 0.65315053]\n [0.29471163 0.70528837]\n [0.17787844 0.82212156]\n [0.20143612 0.79856388]\n [0.18315069 0.81684931]\n [0.18487421 0.81512579]\n [0.3310149  0.6689851 ]\n [0.32066455 0.67933545]\n [0.20143612 0.79856388]\n [0.3305752  0.6694248 ]\n [0.19767283 0.80232717]\n [0.33344152 0.66655848]\n [0.1357204  0.8642796 ]\n [0.20539016 0.79460984]\n [0.28083009 0.71916991]\n [0.14086637 0.85913363]\n [0.36849597 0.63150403]\n [0.1709724  0.8290276 ]\n [0.33869843 0.66130157]\n [0.18682978 0.81317022]\n [0.27688694 0.72311306]\n [0.33082841 0.66917159]\n [0.35760011 0.64239989]\n [0.31126966 0.68873034]\n [0.24926176 0.75073824]\n [0.35220607 0.64779393]\n [0.35489848 0.64510152]\n [0.22560346 0.77439654]\n [0.34134199 0.65865801]\n [0.13088364 0.86911636]\n [0.30504508 0.69495492]\n [0.29369727 0.70630273]\n [0.30459989 0.69540011]\n [0.3204811  0.6795189 ]\n [0.24263772 0.75736228]\n [0.29514851 0.70485149]\n [0.33869843 0.66130157]\n [0.15972809 0.84027191]\n [0.29632248 0.70367752]\n [0.30313983 0.69686017]\n [0.34399545 0.65600455]\n [0.18862609 0.81137391]\n [0.29532377 0.70467623]\n [0.35220607 0.64779393]\n [0.17264863 0.82735137]\n [0.34436407 0.65563593]\n [0.30754813 0.69245187]\n [0.33344152 0.66655848]\n [0.29270372 0.70729628]\n [0.29290262 0.70709738]\n [0.15575919 0.84424081]\n [0.31044837 0.68955163]\n [0.17929834 0.82070166]\n [0.3256335  0.6743665 ]\n [0.16554421 0.83445579]\n [0.13292286 0.86707714]\n [0.18327674 0.81672326]\n [0.26524997 0.73475003]\n [0.30504508 0.69495492]\n [0.19968238 0.80031762]\n [0.26220034 0.73779966]\n [0.19212766 0.80787234]\n [0.29514851 0.70485149]\n [0.37124154 0.62875846]\n [0.19043564 0.80956436]\n [0.33082841 0.66917159]\n [0.19212766 0.80787234]\n [0.25371366 0.74628634]\n [0.29287813 0.70712187]\n [0.19043564 0.80956436]]\n\n\n\nFor lbfgs solver and C value = 0.5, \naccuracy is 74.28571428571429 %\nPredicted Probabilities ar:\n[[0.51119925 0.48880075]\n [0.38141367 0.61858633]\n [0.02933522 0.97066478]\n [0.04339293 0.95660707]\n [0.0295373  0.9704627 ]\n [0.03423794 0.96576206]\n [0.45150065 0.54849935]\n [0.41235983 0.58764017]\n [0.04339293 0.95660707]\n [0.45455105 0.54544895]\n [0.04019835 0.95980165]\n [0.4489612  0.5510388 ]\n [0.02039739 0.97960261]\n [0.04911962 0.95088038]\n [0.28288756 0.71711244]\n [0.01317575 0.98682425]\n [0.5900139  0.4099861 ]\n [0.02391688 0.97608312]\n [0.46877465 0.53122535]\n [0.03349945 0.96650055]\n [0.26676606 0.73323394]\n [0.43911094 0.56088906]\n [0.55092621 0.44907379]\n [0.40076014 0.59923986]\n [0.22095323 0.77904677]\n [0.53111202 0.46888798]\n [0.54103533 0.45896467]\n [0.1738142  0.8261858 ]\n [0.47872239 0.52127761]\n [0.00924123 0.99075877]\n [0.35862847 0.64137153]\n [0.32480498 0.67519502]\n [0.4197151  0.5802849 ]\n [0.4002604  0.5997396 ]\n [0.22286488 0.77713512]\n [0.32280057 0.67719943]\n [0.46877465 0.53122535]\n [0.01889763 0.98110237]\n [0.3448595  0.6551405 ]\n [0.34457578 0.65542422]\n [0.48868704 0.51131296]\n [0.03481571 0.96518429]\n [0.33386194 0.66613806]\n [0.53111202 0.46888798]\n [0.02486631 0.97513369]\n [0.49886702 0.50113298]\n [0.3678574  0.6321426 ]\n [0.4489612  0.5510388 ]\n [0.31414029 0.68585971]\n [0.32252441 0.67747559]\n [0.01766752 0.98233248]\n [0.39826084 0.60173916]\n [0.03909387 0.96090613]\n [0.41956104 0.58043896]\n [0.04325507 0.95674493]\n [0.01155355 0.98844645]\n [0.03100962 0.96899038]\n [0.22959417 0.77040583]\n [0.35862847 0.64137153]\n [0.0438208  0.9561792 ]\n [0.18441299 0.81558701]\n [0.03582567 0.96417433]\n [0.32280057 0.67719943]\n [0.59963035 0.40036965]\n [0.03618174 0.96381826]\n [0.43911094 0.56088906]\n [0.03582567 0.96417433]\n [0.20625588 0.79374412]\n [0.32504735 0.67495265]\n [0.03618174 0.96381826]]\n\n\n\nFor lbfgs solver and C value = 0.05, \naccuracy is 78.57142857142857 %\nPredicted Probabilities ar:\n[[0.43995661 0.56004339]\n [0.34016739 0.65983261]\n [0.09267159 0.90732841]\n [0.11916923 0.88083077]\n [0.09429383 0.90570617]\n [0.1018669  0.8981331 ]\n [0.40166674 0.59833326]\n [0.3767616  0.6232384 ]\n [0.11916923 0.88083077]\n [0.40601961 0.59398039]\n [0.11377817 0.88622183]\n [0.40299237 0.59700763]\n [0.0600792  0.9399208 ]\n [0.12705635 0.87294365]\n [0.29240822 0.70759178]\n [0.05500001 0.94499999]\n [0.49206178 0.50793822]\n [0.08264662 0.91735338]\n [0.4156597  0.5843403 ]\n [0.10072285 0.89927715]\n [0.27930922 0.72069078]\n [0.39670578 0.60329422]\n [0.46591623 0.53408377]\n [0.36344656 0.63655344]\n [0.2392131  0.7607869 ]\n [0.4529044  0.5470956 ]\n [0.45940339 0.54059661]\n [0.19681443 0.80318557]\n [0.42203653 0.57796347]\n [0.04450668 0.95549332]\n [0.34469899 0.65530101]\n [0.3176688  0.6823312 ]\n [0.36406659 0.63593341]\n [0.37191705 0.62808295]\n [0.23107652 0.76892348]\n [0.32142855 0.67857145]\n [0.4156597  0.5843403 ]\n [0.07134992 0.92865008]\n [0.32791661 0.67208339]\n [0.33354341 0.66645659]\n [0.42843946 0.57156054]\n [0.10312073 0.89687927]\n [0.32595676 0.67404324]\n [0.4529044  0.5470956 ]\n [0.08465468 0.91534532]\n [0.43216174 0.56783826]\n [0.35064043 0.64935957]\n [0.40299237 0.59700763]\n [0.31574142 0.68425858]\n [0.32098595 0.67901405]\n [0.06630984 0.93369016]\n [0.36698464 0.63301536]\n [0.10242383 0.89757617]\n [0.38423625 0.61576375]\n [0.09717684 0.90282316]\n [0.04846667 0.95153333]\n [0.09607526 0.90392474]\n [0.25371806 0.74628194]\n [0.34469899 0.65530101]\n [0.11859177 0.88140823]\n [0.24659421 0.75340579]\n [0.10609069 0.89390931]\n [0.32142855 0.67857145]\n [0.49861058 0.50138942]\n [0.105569   0.894431  ]\n [0.39670578 0.60329422]\n [0.10609069 0.89390931]\n [0.23665554 0.76334446]\n [0.32022731 0.67977269]\n [0.105569   0.894431  ]]\n\n\n\nFor lbfgs solver and C value = 0.02, \naccuracy is 78.57142857142857 %\nPredicted Probabilities ar:\n[[0.38769344 0.61230656]\n [0.3137708  0.6862292 ]\n [0.14068089 0.85931911]\n [0.1680167  0.8319833 ]\n [0.14470093 0.85529907]\n [0.14946123 0.85053877]\n [0.36279858 0.63720142]\n [0.34659249 0.65340751]\n [0.1680167  0.8319833 ]\n [0.36417585 0.63582415]\n [0.16312532 0.83687468]\n [0.36524257 0.63475743]\n [0.09792929 0.90207071]\n [0.17404939 0.82595061]\n [0.28818715 0.71181285]\n [0.09897712 0.90102288]\n [0.42179925 0.57820075]\n [0.13151768 0.86848232]\n [0.37348975 0.62651025]\n [0.15004745 0.84995255]\n [0.28050074 0.71949926]\n [0.3611481  0.6388519 ]\n [0.40463123 0.59536877]\n [0.33470382 0.66529618]\n [0.24588489 0.75411511]\n [0.39613119 0.60386881]\n [0.40037371 0.59962629]\n [0.21310214 0.78689786]\n [0.37764143 0.62235857]\n [0.0872474  0.9127526 ]\n [0.32424782 0.67575218]\n [0.30617648 0.69382352]\n [0.32921544 0.67078456]\n [0.34497583 0.65502417]\n [0.23757123 0.76242877]\n [0.3089289  0.6910711 ]\n [0.37348975 0.62651025]\n [0.11897397 0.88102603]\n [0.31148066 0.68851934]\n [0.31879486 0.68120514]\n [0.38181113 0.61818887]\n [0.15231922 0.84768078]\n [0.3104567  0.6895433 ]\n [0.39613119 0.60386881]\n [0.13355299 0.86644701]\n [0.38318229 0.61681771]\n [0.32813882 0.67186118]\n [0.36524257 0.63475743]\n [0.30516223 0.69483777]\n [0.30714769 0.69285231]\n [0.11364329 0.88635671]\n [0.33572174 0.66427826]\n [0.14562191 0.85437809]\n [0.35301989 0.64698011]\n [0.13380043 0.86619957]\n [0.09049498 0.90950502]\n [0.14558765 0.85441235]\n [0.26298801 0.73701199]\n [0.32424782 0.67575218]\n [0.16654616 0.83345384]\n [0.25898313 0.74101687]\n [0.15600407 0.84399593]\n [0.3089289  0.6910711 ]\n [0.42612269 0.57387731]\n [0.15461913 0.84538087]\n [0.3611481  0.6388519 ]\n [0.15600407 0.84399593]\n [0.24863362 0.75136638]\n [0.30667966 0.69332034]\n [0.15461913 0.84538087]]\n\n\n\nFor lbfgs solver and C value = 0.2, \naccuracy is 75.71428571428571 %\nPredicted Probabilities ar:\n[[0.49345188 0.50654812]\n [0.3701639  0.6298361 ]\n [0.04455767 0.95544233]\n [0.06324743 0.93675257]\n [0.04485316 0.95514684]\n [0.05116654 0.94883346]\n [0.43928662 0.56071338]\n [0.40388575 0.59611425]\n [0.06324743 0.93675257]\n [0.44410544 0.55589456]\n [0.05907887 0.94092113]\n [0.43807383 0.56192617]\n [0.0295907  0.9704093 ]\n [0.07033809 0.92966191]\n [0.28710353 0.71289647]\n [0.02156216 0.97843784]\n [0.56569083 0.43430917]\n [0.03725981 0.96274019]\n [0.45602349 0.54397651]\n [0.04999169 0.95000831]\n [0.2707636  0.7292364 ]\n [0.42915645 0.57084355]\n [0.52972703 0.47027297]\n [0.3914629  0.6085371 ]\n [0.22657184 0.77342816]\n [0.51160473 0.48839527]\n [0.52067268 0.47932732]\n [0.17908901 0.82091099]\n [0.46504433 0.53495567]\n [0.01569058 0.98430942]\n [0.35718045 0.64281955]\n [0.32375302 0.67624698]\n [0.40461525 0.59538475]\n [0.39399831 0.60600169]\n [0.22428796 0.77571204]\n [0.32456624 0.67543376]\n [0.45602349 0.54397651]\n [0.0302135  0.9697865 ]\n [0.34095734 0.65904266]\n [0.34247624 0.65752376]\n [0.47408811 0.52591189]\n [0.05174463 0.94825537]\n [0.33367067 0.66632933]\n [0.51160473 0.48839527]\n [0.03858444 0.96141556]\n [0.48218042 0.51781958]\n [0.36556    0.63444   ]\n [0.43807383 0.56192617]\n [0.31665736 0.68334264]\n [0.32477348 0.67522652]\n [0.02792409 0.97207591]\n [0.39257289 0.60742711]\n [0.05584409 0.94415591]\n [0.4114644  0.5885356 ]\n [0.05847347 0.94152653]\n [0.01873806 0.98126194]\n [0.04665329 0.95334671]\n [0.2364386  0.7635614 ]\n [0.35718045 0.64281955]\n [0.06353986 0.93646014]\n [0.21364416 0.78635584]\n [0.05330646 0.94669354]\n [0.32456624 0.67543376]\n [0.57458959 0.42541041]\n [0.05355556 0.94644444]\n [0.42915645 0.57084355]\n [0.05330646 0.94669354]\n [0.21533176 0.78466824]\n [0.3256469  0.6743531 ]\n [0.05355556 0.94644444]]\n\n\n\nFor liblinear solver and C value = 1, \naccuracy is 71.42857142857143 %\nPredicted Probabilities ar:\n[[0.52329119 0.47670881]\n [0.39312075 0.60687925]\n [0.02860977 0.97139023]\n [0.04250212 0.95749788]\n [0.02877408 0.97122592]\n [0.03346381 0.96653619]\n [0.46273012 0.53726988]\n [0.42285055 0.57714945]\n [0.04250212 0.95749788]\n [0.46561365 0.53438635]\n [0.03933041 0.96066959]\n [0.45987955 0.54012045]\n [0.02043956 0.97956044]\n [0.04824552 0.95175448]\n [0.29018418 0.70981582]\n [0.01278555 0.98721445]\n [0.60268948 0.39731052]\n [0.0232345  0.9767655 ]\n [0.48001948 0.51998052]\n [0.03272578 0.96727422]\n [0.27571307 0.72428693]\n [0.44985439 0.55014561]\n [0.56339648 0.43660352]\n [0.41389566 0.58610434]\n [0.22908984 0.77091016]\n [0.54341419 0.45658581]\n [0.55342691 0.44657309]\n [0.18082596 0.81917404]\n [0.49011799 0.50988201]\n [0.00896578 0.99103422]\n [0.36770443 0.63229557]\n [0.33563518 0.66436482]\n [0.43229661 0.56770339]\n [0.4102372  0.5897628 ]\n [0.23099061 0.76900939]\n [0.33096951 0.66903049]\n [0.48001948 0.51998052]\n [0.01830021 0.98169979]\n [0.3565264  0.6434736 ]\n [0.35216893 0.64783107]\n [0.50022457 0.49977543]\n [0.0340301  0.9659699 ]\n [0.3425613  0.6574387 ]\n [0.54341419 0.45658581]\n [0.02416999 0.97583001]\n [0.50934503 0.49065497]\n [0.37715392 0.62284608]\n [0.45987955 0.54012045]\n [0.3220788  0.6779212 ]\n [0.33070917 0.66929083]\n [0.01720825 0.98279175]\n [0.40852734 0.59147266]\n [0.03860669 0.96139331]\n [0.42993362 0.57006638]\n [0.04332356 0.95667644]\n [0.01120857 0.98879143]\n [0.03026058 0.96973942]\n [0.23721954 0.76278046]\n [0.36770443 0.63229557]\n [0.0429714  0.9570286 ]\n [0.16368273 0.83631727]\n [0.03499504 0.96500496]\n [0.33096951 0.66903049]\n [0.61232965 0.38767035]\n [0.0353845  0.9646155 ]\n [0.44985439 0.55014561]\n [0.03499504 0.96500496]\n [0.21304874 0.78695126]\n [0.33351443 0.66648557]\n [0.0353845  0.9646155 ]]\n\n\n\nFor liblinear solver and C value = 0.1, \naccuracy is 74.28571428571429 %\nPredicted Probabilities ar:\n[[0.51024982 0.48975018]\n [0.40295067 0.59704933]\n [0.0979815  0.9020185 ]\n [0.12802981 0.87197019]\n [0.09898222 0.90101778]\n [0.10872616 0.89127384]\n [0.46678633 0.53321367]\n [0.43804807 0.56195193]\n [0.12802981 0.87197019]\n [0.47632619 0.52367381]\n [0.1216913  0.8783087 ]\n [0.4693442  0.5306558 ]\n [0.06574675 0.93425325]\n [0.13684591 0.86315409]\n [0.34159024 0.65840976]\n [0.05658764 0.94341236]\n [0.56784868 0.43215132]\n [0.08669851 0.91330149]\n [0.48381599 0.51618401]\n [0.10604135 0.89395865]\n [0.3337304  0.6662696 ]\n [0.46212607 0.53787393]\n [0.53918003 0.46081997]\n [0.43376771 0.56623229]\n [0.29021958 0.70978042]\n [0.52473568 0.47526432]\n [0.53196455 0.46803545]\n [0.23593302 0.76406698]\n [0.4910636  0.5089364 ]\n [0.04568386 0.95431614]\n [0.40495555 0.59504445]\n [0.38029507 0.61970493]\n [0.431153   0.568847  ]\n [0.43344149 0.56655851]\n [0.27416835 0.72583165]\n [0.37733016 0.62266984]\n [0.48381599 0.51618401]\n [0.07423289 0.92576711]\n [0.39160972 0.60839028]\n [0.38161595 0.61838405]\n [0.49831497 0.50168503]\n [0.10882293 0.89117707]\n [0.38174221 0.61825779]\n [0.52473568 0.47526432]\n [0.08902323 0.91097677]\n [0.49536347 0.50463653]\n [0.41196465 0.58803535]\n [0.4693442  0.5306558 ]\n [0.37053901 0.62946099]\n [0.37856904 0.62143096]\n [0.06818439 0.93181561]\n [0.43196816 0.56803184]\n [0.11074667 0.88925333]\n [0.4477403  0.5522597 ]\n [0.10722868 0.89277132]\n [0.04869999 0.95130001]\n [0.10066577 0.89933423]\n [0.302292   0.697708  ]\n [0.40495555 0.59504445]\n [0.12688729 0.87311271]\n [0.28148388 0.71851612]\n [0.11269153 0.88730847]\n [0.37733016 0.62266984]\n [0.57495297 0.42504703]\n [0.11166835 0.88833165]\n [0.46212607 0.53787393]\n [0.11269153 0.88730847]\n [0.28405546 0.71594454]\n [0.37491947 0.62508053]\n [0.11166835 0.88833165]]\n\n\n\nFor liblinear solver and C value = 0.01, \naccuracy is 68.57142857142857 %\nPredicted Probabilities ar:\n[[0.5034238  0.4965762 ]\n [0.45206111 0.54793889]\n [0.30814132 0.69185868]\n [0.34259428 0.65740572]\n [0.32025894 0.67974106]\n [0.31680537 0.68319463]\n [0.48830185 0.51169815]\n [0.47823073 0.52176927]\n [0.34259428 0.65740572]\n [0.4934056  0.5065944 ]\n [0.33806706 0.66193294]\n [0.49662231 0.50337769]\n [0.24891907 0.75108093]\n [0.3419095  0.6580905 ]\n [0.43751789 0.56248211]\n [0.25760497 0.74239503]\n [0.52357188 0.47642812]\n [0.30450278 0.69549722]\n [0.50166363 0.49833637]\n [0.3195971  0.6804029 ]\n [0.44276988 0.55723012]\n [0.49410185 0.50589815]\n [0.51350333 0.48649667]\n [0.47203498 0.52796502]\n [0.40944694 0.59055306]\n [0.50846442 0.49153558]\n [0.51098415 0.48901585]\n [0.37457647 0.62542353]\n [0.50418423 0.49581577]\n [0.25299635 0.74700365]\n [0.46824113 0.53175887]\n [0.46024688 0.53975312]\n [0.46206917 0.53793083]\n [0.48402425 0.51597575]\n [0.38818191 0.61181809]\n [0.45821326 0.54178674]\n [0.50166363 0.49833637]\n [0.28973585 0.71026415]\n [0.4569882  0.5430118 ]\n [0.45494718 0.54505282]\n [0.50670462 0.49329538]\n [0.32179362 0.67820638]\n [0.45245776 0.54754224]\n [0.50846442 0.49153558]\n [0.30664231 0.69335769]\n [0.49515584 0.50484416]\n [0.47075244 0.52924756]\n [0.49662231 0.50337769]\n [0.45571125 0.54428875]\n [0.45567623 0.54432377]\n [0.27794059 0.72205941]\n [0.46744865 0.53255135]\n [0.30501081 0.69498919]\n [0.48906194 0.51093806]\n [0.28058426 0.71941574]\n [0.24921106 0.75078894]\n [0.31522806 0.68477194]\n [0.43036995 0.56963005]\n [0.46824113 0.53175887]\n [0.33513632 0.66486368]\n [0.41925226 0.58074774]\n [0.33133167 0.66866833]\n [0.45821326 0.54178674]\n [0.52608635 0.47391365]\n [0.32399805 0.67600195]\n [0.49410185 0.50589815]\n [0.33133167 0.66866833]\n [0.41737926 0.58262074]\n [0.44996108 0.55003892]\n [0.32399805 0.67600195]]\n\n\n\nFor liblinear solver and C value = 0.5, \naccuracy is 72.85714285714285 %\nPredicted Probabilities ar:\n[[0.52058513 0.47941487]\n [0.39364864 0.60635136]\n [0.03899647 0.96100353]\n [0.05650602 0.94349398]\n [0.03915316 0.96084684]\n [0.04519716 0.95480284]\n [0.46290143 0.53709857]\n [0.42489662 0.57510338]\n [0.05650602 0.94349398]\n [0.46797682 0.53202318]\n [0.05253746 0.94746254]\n [0.46116938 0.53883062]\n [0.0272122  0.9727878 ]\n [0.06340269 0.93659731]\n [0.29880961 0.70119039]\n [0.01829731 0.98170269]\n [0.5963934  0.4036066 ]\n [0.03217004 0.96782996]\n [0.4803557  0.5196443 ]\n [0.04403072 0.95596928]\n [0.28565063 0.71434937]\n [0.45161563 0.54838437]\n [0.55883209 0.44116791]\n [0.41775461 0.58224539]\n [0.23960087 0.76039913]\n [0.53976715 0.46023285]\n [0.54931772 0.45068228]\n [0.1891469  0.8108531 ]\n [0.4899742  0.5100258 ]\n [0.01313797 0.98686203]\n [0.37440636 0.62559364]\n [0.34365711 0.65634289]\n [0.43095288 0.56904712]\n [0.4138235  0.5861765 ]\n [0.23752254 0.76247746]\n [0.33908023 0.66091977]\n [0.4803557  0.5196443 ]\n [0.02574793 0.97425207]\n [0.36284149 0.63715851]\n [0.35638528 0.64361472]\n [0.49960013 0.50039987]\n [0.04568041 0.95431959]\n [0.34934531 0.65065469]\n [0.53976715 0.46023285]\n [0.03339087 0.96660913]\n [0.5062641  0.4937359 ]\n [0.38346891 0.61653109]\n [0.46116938 0.53883062]\n [0.33050436 0.66949564]\n [0.3394747  0.6605253 ]\n [0.02404267 0.97595733]\n [0.41323818 0.58676182]\n [0.05066132 0.94933868]\n [0.43262156 0.56737844]\n [0.05492401 0.94507599]\n [0.01580724 0.98419276]\n [0.04090035 0.95909965]\n [0.24802973 0.75197027]\n [0.37440636 0.62559364]\n [0.05687868 0.94312132]\n [0.19876097 0.80123903]\n [0.04707526 0.95292474]\n [0.33908023 0.66091977]\n [0.60562745 0.39437255]\n [0.04738885 0.95261115]\n [0.45161563 0.54838437]\n [0.04707526 0.95292474]\n [0.22516494 0.77483506]\n [0.34064363 0.65935637]\n [0.04738885 0.95261115]]\n\n\n\nFor liblinear solver and C value = 0.05, \naccuracy is 74.28571428571429 %\nPredicted Probabilities ar:\n[[0.50602735 0.49397265]\n [0.41333378 0.58666622]\n [0.14661826 0.85338174]\n [0.1817012  0.8182988 ]\n [0.1498586  0.8501414 ]\n [0.15855274 0.84144726]\n [0.47143182 0.52856818]\n [0.44849932 0.55150068]\n [0.1817012  0.8182988 ]\n [0.48094504 0.51905496]\n [0.17493708 0.82506292]\n [0.47650798 0.52349202]\n [0.10059698 0.89940302]\n [0.18908447 0.81091553]\n [0.36929903 0.63070097]\n [0.09537756 0.90462244]\n [0.55200815 0.44799185]\n [0.13511879 0.86488121]\n [0.48803528 0.51196472]\n [0.15619495 0.84380505]\n [0.36556013 0.63443987]\n [0.47075294 0.52924706]\n [0.52907944 0.47092056]\n [0.44388688 0.55611312]\n [0.32344844 0.67655156]\n [0.51756274 0.48243726]\n [0.52332419 0.47667581]\n [0.27102516 0.72897484]\n [0.49380448 0.50619552]\n [0.08271245 0.91728755]\n [0.42382195 0.57617805]\n [0.40378491 0.59621509]\n [0.43588935 0.56411065]\n [0.44782548 0.55217452]\n [0.30204815 0.69795185]\n [0.40144644 0.59855356]\n [0.48803528 0.51196472]\n [0.11992319 0.88007681]\n [0.41001343 0.58998657]\n [0.40103804 0.59896196]\n [0.49957532 0.50042468]\n [0.15926167 0.84073833]\n [0.40210131 0.59789869]\n [0.51756274 0.48243726]\n [0.13783929 0.86216071]\n [0.49205382 0.50794618]\n [0.42946883 0.57053117]\n [0.47650798 0.52349202]\n [0.39591233 0.60408767]\n [0.40187617 0.59812383]\n [0.11060603 0.88939397]\n [0.44192909 0.55807091]\n [0.15590099 0.84409901]\n [0.45926765 0.54073235]\n [0.14492272 0.85507728]\n [0.08437677 0.91562323]\n [0.15020605 0.84979395]\n [0.33922832 0.66077168]\n [0.42382195 0.57617805]\n [0.17869354 0.82130646]\n [0.32300141 0.67699859]\n [0.16516526 0.83483474]\n [0.40144644 0.59855356]\n [0.55770978 0.44229022]\n [0.16237701 0.83762299]\n [0.47075294 0.52924706]\n [0.16516526 0.83483474]\n [0.32272146 0.67727854]\n [0.39656416 0.60343584]\n [0.16237701 0.83762299]]\n\n\n\nFor liblinear solver and C value = 0.02, \naccuracy is 72.85714285714285 %\nPredicted Probabilities ar:\n[[0.50350612 0.49649388]\n [0.43392555 0.56607445]\n [0.23371623 0.76628377]\n [0.27142253 0.72857747]\n [0.24248315 0.75751685]\n [0.24475835 0.75524165]\n [0.48076123 0.51923877]\n [0.46563636 0.53436364]\n [0.27142253 0.72857747]\n [0.48808333 0.51191667]\n [0.26546464 0.73453536]\n [0.48856361 0.51143639]\n [0.17380631 0.82619369]\n [0.27425351 0.72574649]\n [0.4092327  0.5907673 ]\n [0.17722658 0.82277342]\n [0.53379385 0.46620615]\n [0.22582221 0.77417779]\n [0.49614651 0.50385349]\n [0.24511384 0.75488616]\n [0.4114238  0.5885762 ]\n [0.48477392 0.51522608]\n [0.51866713 0.48133287]\n [0.45964358 0.54035642]\n [0.37269235 0.62730765]\n [0.51108918 0.48891082]\n [0.51487901 0.48512099]\n [0.32836072 0.67163928]\n [0.49993884 0.50006116]\n [0.16727545 0.83272455]\n [0.45032144 0.54967856]\n [0.4373571  0.5626429 ]\n [0.44888566 0.55111434]\n [0.46963698 0.53036302]\n [0.34895228 0.65104772]\n [0.43535128 0.56464872]\n [0.49614651 0.50385349]\n [0.2092995  0.7907005 ]\n [0.43713558 0.56286442]\n [0.43210811 0.56789189]\n [0.50373118 0.49626882]\n [0.24793157 0.75206843]\n [0.43140515 0.56859485]\n [0.51108918 0.48891082]\n [0.22848529 0.77151471]\n [0.49236532 0.50763468]\n [0.45407917 0.54592083]\n [0.48856361 0.51143639]\n [0.43162599 0.56837401]\n [0.43385686 0.56614314]\n [0.19688298 0.80311702]\n [0.45610957 0.54389043]\n [0.23539807 0.76460193]\n [0.47720021 0.52279979]\n [0.21432501 0.78567499]\n [0.1656057  0.8343943 ]\n [0.23954358 0.76045642]\n [0.3931881  0.6068119 ]\n [0.45032144 0.54967856]\n [0.26528913 0.73471087]\n [0.38015629 0.61984371]\n [0.25668593 0.74331407]\n [0.43535128 0.56464872]\n [0.53756693 0.46243307]\n [0.25077092 0.74922908]\n [0.48477392 0.51522608]\n [0.25668593 0.74331407]\n [0.37835614 0.62164386]\n [0.42768806 0.57231194]\n [0.25077092 0.74922908]]\n\n\n\nFor liblinear solver and C value = 0.2, \naccuracy is 72.85714285714285 %\nPredicted Probabilities ar:\n[[0.51516521 0.48483479]\n [0.39695841 0.60304159]\n [0.06471368 0.93528632]\n [0.08896835 0.91103165]\n [0.06499234 0.93500766]\n [0.07344853 0.92655147]\n [0.46423281 0.53576719]\n [0.43062322 0.56937678]\n [0.08896835 0.91103165]\n [0.47229954 0.52770046]\n [0.0836088  0.9163912 ]\n [0.46460517 0.53539483]\n [0.04376052 0.95623948]\n [0.09745767 0.90254233]\n [0.31899585 0.68100415]\n [0.03363236 0.96636764]\n [0.58240892 0.41759108]\n [0.05523303 0.94476697]\n [0.48155367 0.51844633]\n [0.07137311 0.92862689]\n [0.30819382 0.69180618]\n [0.45615904 0.54384096]\n [0.54901082 0.45098918]\n [0.42553513 0.57446487]\n [0.26344402 0.73655598]\n [0.53212497 0.46787503]\n [0.54057954 0.45942046]\n [0.21008652 0.78991348]\n [0.49004631 0.50995369]\n [0.02552767 0.97447233]\n [0.38914591 0.61085409]\n [0.36110183 0.63889817]\n [0.42992448 0.57007552]\n [0.42267283 0.57732717]\n [0.25388922 0.74611078]\n [0.35734666 0.64265334]\n [0.48155367 0.51844633]\n [0.04572867 0.95427133]\n [0.37658129 0.62341871]\n [0.36752171 0.63247829]\n [0.49854471 0.50145529]\n [0.07365962 0.92634038]\n [0.3648448  0.6351552 ]\n [0.53212497 0.46787503]\n [0.05703423 0.94296577]\n [0.50027947 0.49972053]\n [0.39725761 0.60274239]\n [0.46460517 0.53539483]\n [0.34957725 0.65042275]\n [0.35852968 0.64147032]\n [0.04220425 0.95779575]\n [0.42280775 0.57719225]\n [0.07812232 0.92187768]\n [0.43934691 0.56065309]\n [0.07959488 0.92040512]\n [0.02873165 0.97126835]\n [0.06699557 0.93300443]\n [0.27317539 0.72682461]\n [0.38914591 0.61085409]\n [0.08884709 0.91115291]\n [0.24405699 0.75594301]\n [0.0761186  0.9238814 ]\n [0.35734666 0.64265334]\n [0.59065384 0.40934616]\n [0.07601339 0.92398661]\n [0.45615904 0.54384096]\n [0.0761186  0.9238814 ]\n [0.25281301 0.74718699]\n [0.35700294 0.64299706]\n [0.07601339 0.92398661]]\n\n\n\nFor sag solver and C value = 1, \naccuracy is 72.85714285714285 %\nPredicted Probabilities ar:\n[[0.51845475 0.48154525]\n [0.38662471 0.61337529]\n [0.02326647 0.97673353]\n [0.0350117  0.9649883 ]\n [0.02344804 0.97655196]\n [0.02732953 0.97267047]\n [0.4566511  0.5433489 ]\n [0.41606332 0.58393668]\n [0.0350117  0.9649883 ]\n [0.45828181 0.54171819]\n [0.03232688 0.96767312]\n [0.45333431 0.54666569]\n [0.01662533 0.98337467]\n [0.03995541 0.96004459]\n [0.28125992 0.71874008]\n [0.0101256  0.9898744 ]\n [0.59967201 0.40032799]\n [0.01876203 0.98123797]\n [0.47386233 0.52613767]\n [0.02680429 0.97319571]\n [0.26513159 0.73486841]\n [0.44312513 0.55687487]\n [0.55946119 0.44053881]\n [0.40446905 0.59553095]\n [0.21863917 0.78136083]\n [0.53902399 0.46097601]\n [0.54926337 0.45073663]\n [0.17230624 0.82769376]\n [0.48416397 0.51583603]\n [0.0070032  0.9929968 ]\n [0.35891666 0.64108334]\n [0.32508505 0.67491495]\n [0.42643791 0.57356209]\n [0.40284823 0.59715177]\n [0.22286382 0.77713618]\n [0.32186977 0.67813023]\n [0.47386233 0.52613767]\n [0.01466112 0.98533888]\n [0.34647667 0.65352333]\n [0.3457324  0.6542676 ]\n [0.49447909 0.50552091]\n [0.02790242 0.97209758]\n [0.33391385 0.66608615]\n [0.53902399 0.46097601]\n [0.0195373  0.9804627 ]\n [0.50565998 0.49434002]\n [0.36846945 0.63153055]\n [0.45333431 0.54666569]\n [0.31292647 0.68707353]\n [0.32118862 0.67881138]\n [0.01380138 0.98619862]\n [0.40018531 0.59981469]\n [0.03191481 0.96808519]\n [0.42285849 0.57714151]\n [0.03630453 0.96369547]\n [0.00896582 0.99103418]\n [0.02473271 0.97526729]\n [0.22690526 0.77309474]\n [0.35891666 0.64108334]\n [0.03546643 0.96453357]\n [0.15659186 0.84340814]\n [0.02866938 0.97133062]\n [0.32186977 0.67813023]\n [0.60954009 0.39045991]\n [0.02904421 0.97095579]\n [0.44312513 0.55687487]\n [0.02866938 0.97133062]\n [0.20245089 0.79754911]\n [0.32479618 0.67520382]\n [0.02904421 0.97095579]]\n\n\n\nFor sag solver and C value = 0.1, \naccuracy is 77.14285714285715 %\nPredicted Probabilities ar:\n[[0.47118305 0.52881695]\n [0.35721743 0.64278257]\n [0.06429824 0.93570176]\n [0.08720265 0.91279735]\n [0.06492128 0.93507872]\n [0.07242016 0.92757984]\n [0.42387127 0.57612873]\n [0.39303517 0.60696483]\n [0.08720265 0.91279735]\n [0.42919516 0.57080484]\n [0.08225356 0.91774644]\n [0.42389048 0.57610952]\n [0.04156774 0.95843226]\n [0.09512499 0.90487501]\n [0.29076968 0.70923032]\n [0.03400454 0.96599546]\n [0.53492931 0.46507069]\n [0.05534289 0.94465711]\n [0.43955028 0.56044972]\n [0.07097677 0.92902323]\n [0.27511501 0.72488499]\n [0.41611552 0.58388448]\n [0.50306865 0.49693135]\n [0.37986098 0.62013902]\n [0.23270041 0.76729959]\n [0.48711274 0.51288726]\n [0.49508945 0.50491055]\n [0.18649238 0.81350762]\n [0.44742758 0.55257242]\n [0.02590821 0.97409179]\n [0.35335787 0.64664213]\n [0.32182432 0.67817568]\n [0.3870353  0.6129647 ]\n [0.38546614 0.61453386]\n [0.22697867 0.77302133]\n [0.32475992 0.67524008]\n [0.43955028 0.56044972]\n [0.04618334 0.95381666]\n [0.33589448 0.66410552]\n [0.33943311 0.66056689]\n [0.45533135 0.54466865]\n [0.07311042 0.92688958]\n [0.33178048 0.66821952]\n [0.48711274 0.51288726]\n [0.05703542 0.94296458]\n [0.46129266 0.53870734]\n [0.36068459 0.63931541]\n [0.42389048 0.57610952]\n [0.31780019 0.68219981]\n [0.32496328 0.67503672]\n [0.04253596 0.95746404]\n [0.3832461  0.6167539 ]\n [0.07576523 0.92423477]\n [0.40069371 0.59930629]\n [0.07536596 0.92463404]\n [0.02957818 0.97042182]\n [0.06688109 0.93311891]\n [0.24445431 0.75554569]\n [0.35335787 0.64664213]\n [0.08719639 0.91280361]\n [0.23171152 0.76828848]\n [0.07530849 0.92469151]\n [0.32475992 0.67524008]\n [0.54286025 0.45713975]\n [0.07530302 0.92469698]\n [0.41611552 0.58388448]\n [0.07530849 0.92469151]\n [0.22541308 0.77458692]\n [0.32474266 0.67525734]\n [0.07530302 0.92469698]]\n\n\n\nFor sag solver and C value = 0.01, \naccuracy is 78.57142857142857 %\nPredicted Probabilities ar:\n[[0.34691458 0.65308542]\n [0.29477417 0.70522583]\n [0.17792062 0.82207938]\n [0.20148355 0.79851645]\n [0.18319202 0.81680798]\n [0.1849188  0.8150812 ]\n [0.33107607 0.66892393]\n [0.3207231  0.6792769 ]\n [0.20148355 0.79851645]\n [0.33064688 0.66935312]\n [0.197719   0.802281  ]\n [0.33350664 0.66649336]\n [0.13575667 0.86424333]\n [0.20543646 0.79456354]\n [0.28088496 0.71911504]\n [0.14090062 0.85909938]\n [0.36856631 0.63143369]\n [0.17101435 0.82898565]\n [0.33876489 0.66123511]\n [0.18687004 0.81312996]\n [0.27694673 0.72305327]\n [0.33089286 0.66910714]\n [0.35766784 0.64233216]\n [0.31133607 0.68866393]\n [0.24932319 0.75067681]\n [0.35227249 0.64772751]\n [0.35496556 0.64503444]\n [0.2256518  0.7743482 ]\n [0.34140912 0.65859088]\n [0.1309171  0.8690829 ]\n [0.3051098  0.6948902 ]\n [0.29376192 0.70623808]\n [0.3046652  0.6953348 ]\n [0.32054288 0.67945712]\n [0.24268634 0.75731366]\n [0.29521046 0.70478954]\n [0.33876489 0.66123511]\n [0.15976844 0.84023156]\n [0.29638475 0.70361525]\n [0.30318815 0.69681185]\n [0.34406325 0.65593675]\n [0.18866694 0.81133306]\n [0.29538264 0.70461736]\n [0.35227249 0.64772751]\n [0.17269117 0.82730883]\n [0.34442244 0.65557756]\n [0.30761354 0.69238646]\n [0.33350664 0.66649336]\n [0.29276499 0.70723501]\n [0.29296759 0.70703241]\n [0.15579222 0.84420778]\n [0.31051511 0.68948489]\n [0.17934151 0.82065849]\n [0.32569662 0.67430338]\n [0.16558575 0.83441425]\n [0.13295195 0.86704805]\n [0.18331585 0.81668415]\n [0.26530636 0.73469364]\n [0.3051098  0.6948902 ]\n [0.19972682 0.80027318]\n [0.26225042 0.73774958]\n [0.19217198 0.80782802]\n [0.29521046 0.70478954]\n [0.37131253 0.62868747]\n [0.19047707 0.80952293]\n [0.33089286 0.66910714]\n [0.19217198 0.80782802]\n [0.25377288 0.74622712]\n [0.29293632 0.70706368]\n [0.19047707 0.80952293]]\n\n\n\nFor sag solver and C value = 0.5, \naccuracy is 74.28571428571429 %\nPredicted Probabilities ar:\n[[0.51121458 0.48878542]\n [0.38140863 0.61859137]\n [0.02933561 0.97066439]\n [0.04339884 0.95660116]\n [0.02953734 0.97046266]\n [0.03424025 0.96575975]\n [0.45149491 0.54850509]\n [0.41234056 0.58765944]\n [0.04339884 0.95660116]\n [0.45458337 0.54541663]\n [0.04020275 0.95979725]\n [0.44897123 0.55102877]\n [0.02040281 0.97959719]\n [0.04912526 0.95087474]\n [0.28284678 0.71715322]\n [0.01317743 0.98682257]\n [0.59005601 0.40994399]\n [0.02391704 0.97608296]\n [0.46879176 0.53120824]\n [0.03349881 0.96650119]\n [0.2668034  0.7331966 ]\n [0.43911745 0.56088255]\n [0.55095534 0.44904466]\n [0.40084145 0.59915855]\n [0.22098866 0.77901134]\n [0.53113432 0.46886568]\n [0.54106107 0.45893893]\n [0.17380941 0.82619059]\n [0.47874306 0.52125694]\n [0.00924215 0.99075785]\n [0.35862605 0.64137395]\n [0.32486848 0.67513152]\n [0.41972363 0.58027637]\n [0.40025322 0.59974678]\n [0.22286518 0.77713482]\n [0.32278594 0.67721406]\n [0.46879176 0.53120824]\n [0.01889699 0.98110301]\n [0.3449169  0.6550831 ]\n [0.344518   0.655482  ]\n [0.48871125 0.51128875]\n [0.03481551 0.96518449]\n [0.33383603 0.66616397]\n [0.53113432 0.46886568]\n [0.02486681 0.97513319]\n [0.49885942 0.50114058]\n [0.36785822 0.63214178]\n [0.44897123 0.55102877]\n [0.31412284 0.68587716]\n [0.32251923 0.67748077]\n [0.01766942 0.98233058]\n [0.39826692 0.60173308]\n [0.03909662 0.96090338]\n [0.41956062 0.58043938]\n [0.04325863 0.95674137]\n [0.01155013 0.98844987]\n [0.03100817 0.96899183]\n [0.22961547 0.77038453]\n [0.35862605 0.64137395]\n [0.0438241  0.9561759 ]\n [0.18448115 0.81551885]\n [0.03582815 0.96417185]\n [0.32278594 0.67721406]\n [0.59967553 0.40032447]\n [0.03618203 0.96381797]\n [0.43911745 0.56088255]\n [0.03582815 0.96417185]\n [0.20628108 0.79371892]\n [0.3250187  0.6749813 ]\n [0.03618203 0.96381797]]\n\n\n\nFor sag solver and C value = 0.05, \naccuracy is 78.57142857142857 %\nPredicted Probabilities ar:\n[[0.43996288 0.56003712]\n [0.34016695 0.65983305]\n [0.09267365 0.90732635]\n [0.11917871 0.88082129]\n [0.09429914 0.90570086]\n [0.10187017 0.89812983]\n [0.40166881 0.59833119]\n [0.37676099 0.62323901]\n [0.11917871 0.88082129]\n [0.40602328 0.59397672]\n [0.11378671 0.88621329]\n [0.40299943 0.59700057]\n [0.06008364 0.93991636]\n [0.127065   0.872935  ]\n [0.29239605 0.70760395]\n [0.05500109 0.94499891]\n [0.49207376 0.50792624]\n [0.08264899 0.91735101]\n [0.4156682  0.5843318 ]\n [0.10072737 0.89927263]\n [0.27931356 0.72068644]\n [0.39671214 0.60328786]\n [0.46592536 0.53407464]\n [0.36345648 0.63654352]\n [0.23920981 0.76079019]\n [0.45291209 0.54708791]\n [0.45941181 0.54058819]\n [0.19680651 0.80319349]\n [0.42204575 0.57795425]\n [0.0445072  0.9554928 ]\n [0.34469609 0.65530391]\n [0.31767772 0.68232228]\n [0.36406874 0.63593126]\n [0.37192063 0.62807937]\n [0.23107385 0.76892615]\n [0.32142331 0.67857669]\n [0.4156682  0.5843318 ]\n [0.07135032 0.92864968]\n [0.32792235 0.67207765]\n [0.33354128 0.66645872]\n [0.4284494  0.5715506 ]\n [0.10312561 0.89687439]\n [0.32594753 0.67405247]\n [0.45291209 0.54708791]\n [0.08465732 0.91534268]\n [0.43217041 0.56782959]\n [0.35063814 0.64936186]\n [0.40299943 0.59700057]\n [0.31573561 0.68426439]\n [0.32097886 0.67902114]\n [0.06631392 0.93368608]\n [0.36697747 0.63302253]\n [0.10242838 0.89757162]\n [0.38424121 0.61575879]\n [0.09718163 0.90281837]\n [0.04846589 0.95153411]\n [0.09607911 0.90392089]\n [0.25371948 0.74628052]\n [0.34469609 0.65530391]\n [0.11859904 0.88140096]\n [0.24658238 0.75341762]\n [0.10609792 0.89390208]\n [0.32142331 0.67857669]\n [0.49862325 0.50137675]\n [0.10557425 0.89442575]\n [0.39671214 0.60328786]\n [0.10609792 0.89390208]\n [0.23665231 0.76334769]\n [0.32021756 0.67978244]\n [0.10557425 0.89442575]]\n\n\n\nFor sag solver and C value = 0.02, \naccuracy is 78.57142857142857 %\nPredicted Probabilities ar:\n[[0.38765048 0.61234952]\n [0.31370996 0.68629004]\n [0.14066292 0.85933708]\n [0.16798694 0.83201306]\n [0.14467451 0.85532549]\n [0.14944237 0.85055763]\n [0.36275667 0.63724333]\n [0.34655139 0.65344861]\n [0.16798694 0.83201306]\n [0.3641192  0.6358808 ]\n [0.16309623 0.83690377]\n [0.36518567 0.63481433]\n [0.09791316 0.90208684]\n [0.17402803 0.82597197]\n [0.28814991 0.71185009]\n [0.09897516 0.90102484]\n [0.42175522 0.57824478]\n [0.13149335 0.86850665]\n [0.37343234 0.62656766]\n [0.15002842 0.84997158]\n [0.28047609 0.71952391]\n [0.36109147 0.63890853]\n [0.40458769 0.59541231]\n [0.3346911  0.6653089 ]\n [0.24585893 0.75414107]\n [0.39608793 0.60391207]\n [0.40033031 0.59966969]\n [0.21308613 0.78691387]\n [0.37758378 0.62241622]\n [0.08724023 0.91275977]\n [0.3241941  0.6758059 ]\n [0.30615062 0.69384938]\n [0.32915309 0.67084691]\n [0.34492031 0.65507969]\n [0.23755455 0.76244545]\n [0.30887651 0.69112349]\n [0.37343234 0.62656766]\n [0.11895165 0.88104835]\n [0.31146833 0.68853167]\n [0.31875599 0.68124401]\n [0.38175325 0.61824675]\n [0.15229997 0.84770003]\n [0.31041791 0.68958209]\n [0.39608793 0.60391207]\n [0.13352834 0.86647166]\n [0.3831402  0.6168598 ]\n [0.32808477 0.67191523]\n [0.36518567 0.63481433]\n [0.30511018 0.69488982]\n [0.30709556 0.69290444]\n [0.11364101 0.88635899]\n [0.33568151 0.66431849]\n [0.1455988  0.8544012 ]\n [0.3529638  0.6470362 ]\n [0.13377245 0.86622755]\n [0.09047428 0.90952572]\n [0.14556908 0.85443092]\n [0.26296429 0.73703571]\n [0.3241941  0.6758059 ]\n [0.16652551 0.83347449]\n [0.25893905 0.74106095]\n [0.155976   0.844024  ]\n [0.30887651 0.69112349]\n [0.42607855 0.57392145]\n [0.15459965 0.84540035]\n [0.36109147 0.63890853]\n [0.155976   0.844024  ]\n [0.24861087 0.75138913]\n [0.30664112 0.69335888]\n [0.15459965 0.84540035]]\n\n\n\nFor sag solver and C value = 0.2, \naccuracy is 75.71428571428571 %\nPredicted Probabilities ar:\n[[0.4934311  0.5065689 ]\n [0.37016319 0.62983681]\n [0.04455873 0.95544127]\n [0.06324392 0.93675608]\n [0.0448495  0.9551505 ]\n [0.05116826 0.94883174]\n [0.43926226 0.56073774]\n [0.4038594  0.5961406 ]\n [0.06324392 0.93675608]\n [0.44410814 0.55589186]\n [0.05907529 0.94092471]\n [0.4380491  0.5619509 ]\n [0.02958812 0.97041188]\n [0.07033483 0.92966517]\n [0.28709584 0.71290416]\n [0.02156131 0.97843869]\n [0.56567559 0.43432441]\n [0.03726017 0.96273983]\n [0.45599987 0.54400013]\n [0.04998808 0.95001192]\n [0.27071275 0.72928725]\n [0.42913119 0.57086881]\n [0.52970895 0.47029105]\n [0.39141133 0.60858867]\n [0.22655389 0.77344611]\n [0.51158528 0.48841472]\n [0.52065391 0.47934609]\n [0.17906299 0.82093701]\n [0.46502131 0.53497869]\n [0.01568815 0.98431185]\n [0.35717692 0.64282308]\n [0.32370067 0.67629933]\n [0.40461705 0.59538295]\n [0.39397117 0.60602883]\n [0.22426669 0.77573331]\n [0.32456056 0.67543944]\n [0.45599987 0.54400013]\n [0.03021505 0.96978495]\n [0.34090514 0.65909486]\n [0.34245503 0.65754497]\n [0.47406569 0.52593431]\n [0.05174102 0.94825898]\n [0.33366583 0.66633417]\n [0.51158528 0.48841472]\n [0.03858491 0.96141509]\n [0.48216742 0.51783258]\n [0.36555704 0.63444296]\n [0.4380491  0.5619509 ]\n [0.31665118 0.68334882]\n [0.32478063 0.67521937]\n [0.02791896 0.97208104]\n [0.39258606 0.60741394]\n [0.05584674 0.94415326]\n [0.41143816 0.58856184]\n [0.05848034 0.94151966]\n [0.01873746 0.98126254]\n [0.04664967 0.95335033]\n [0.23638973 0.76361027]\n [0.35717692 0.64282308]\n [0.06353643 0.93646357]\n [0.21363429 0.78636571]\n [0.05330281 0.94669719]\n [0.32456056 0.67543944]\n [0.57457508 0.42542492]\n [0.05355197 0.94644803]\n [0.42913119 0.57086881]\n [0.05330281 0.94669719]\n [0.21530306 0.78469694]\n [0.32564155 0.67435845]\n [0.05355197 0.94644803]]\n\n\n\nFor saga solver and C value = 1, \naccuracy is 72.85714285714285 %\nPredicted Probabilities ar:\n[[0.51845656 0.48154344]\n [0.38661575 0.61338425]\n [0.02326665 0.97673335]\n [0.03501265 0.96498735]\n [0.02344789 0.97655211]\n [0.02733011 0.97266989]\n [0.45664778 0.54335222]\n [0.41605674 0.58394326]\n [0.03501265 0.96498735]\n [0.45828687 0.54171313]\n [0.03232754 0.96767246]\n [0.45333299 0.54666701]\n [0.01662491 0.98337509]\n [0.03995657 0.96004343]\n [0.28124923 0.71875077]\n [0.01012578 0.98987422]\n [0.59968034 0.40031966]\n [0.01876201 0.98123799]\n [0.47386272 0.52613728]\n [0.02680418 0.97319582]\n [0.2651307  0.7348693 ]\n [0.44312298 0.55687702]\n [0.55946636 0.44053364]\n [0.40447842 0.59552158]\n [0.2186382  0.7813618 ]\n [0.5390275  0.4609725 ]\n [0.54926771 0.45073229]\n [0.17229639 0.82770361]\n [0.48416522 0.51583478]\n [0.0070031  0.9929969 ]\n [0.35891345 0.64108655]\n [0.32508932 0.67491068]\n [0.42643202 0.57356798]\n [0.40284282 0.59715718]\n [0.22285612 0.77714388]\n [0.32186373 0.67813627]\n [0.47386272 0.52613728]\n [0.01466098 0.98533902]\n [0.34648081 0.65351919]\n [0.34572021 0.65427979]\n [0.49448119 0.50551881]\n [0.02790241 0.97209759]\n [0.33390668 0.66609332]\n [0.5390275  0.4609725 ]\n [0.01953734 0.98046266]\n [0.50566023 0.49433977]\n [0.36846701 0.63153299]\n [0.45333299 0.54666701]\n [0.31291978 0.68708022]\n [0.32118534 0.67881466]\n [0.01380149 0.98619851]\n [0.40018635 0.59981365]\n [0.03191485 0.96808515]\n [0.42285468 0.57714532]\n [0.03630364 0.96369636]\n [0.00896496 0.99103504]\n [0.02473245 0.97526755]\n [0.22690145 0.77309855]\n [0.35891345 0.64108655]\n [0.03546711 0.96453289]\n [0.15707009 0.84292991]\n [0.02866968 0.97133032]\n [0.32186373 0.67813627]\n [0.60954917 0.39045083]\n [0.02904429 0.97095571]\n [0.44312298 0.55687702]\n [0.02866968 0.97133032]\n [0.20244932 0.79755068]\n [0.32478835 0.67521165]\n [0.02904429 0.97095571]]\n\n\n\nFor saga solver and C value = 0.1, \naccuracy is 77.14285714285715 %\nPredicted Probabilities ar:\n[[0.47118012 0.52881988]\n [0.35729439 0.64270561]\n [0.06427672 0.93572328]\n [0.0872014  0.9127986 ]\n [0.06491211 0.93508789]\n [0.07239977 0.92760023]\n [0.42384859 0.57615141]\n [0.3930001  0.6069999 ]\n [0.0872014  0.9127986 ]\n [0.4292974  0.5707026 ]\n [0.08225033 0.91774967]\n [0.42395369 0.57604631]\n [0.04157569 0.95842431]\n [0.09509686 0.90490314]\n [0.29073022 0.70926978]\n [0.03399699 0.96600301]\n [0.5349533  0.4650467 ]\n [0.05533904 0.94466096]\n [0.4396207  0.5603793 ]\n [0.0709463  0.9290537 ]\n [0.27516764 0.72483236]\n [0.41617511 0.58382489]\n [0.50307924 0.49692076]\n [0.37988808 0.62011192]\n [0.23277554 0.76722446]\n [0.48711656 0.51288344]\n [0.49509665 0.50490335]\n [0.18647627 0.81352373]\n [0.4475016  0.5524984 ]\n [0.02590512 0.97409488]\n [0.35342232 0.64657768]\n [0.32190259 0.67809741]\n [0.38712766 0.61287234]\n [0.38551143 0.61448857]\n [0.22698653 0.77301347]\n [0.32480991 0.67519009]\n [0.4396207  0.5603793 ]\n [0.04618005 0.95381995]\n [0.33590204 0.66409796]\n [0.3393885  0.6606115 ]\n [0.45540896 0.54459104]\n [0.07308003 0.92691997]\n [0.33175605 0.66824395]\n [0.48711656 0.51288344]\n [0.05703218 0.94296782]\n [0.46129699 0.53870301]\n [0.36075275 0.63924725]\n [0.42395369 0.57604631]\n [0.31784668 0.68215332]\n [0.32503084 0.67496916]\n [0.04252129 0.95747871]\n [0.38326134 0.61673866]\n [0.07574863 0.92425137]\n [0.40074612 0.59925388]\n [0.07535963 0.92464037]\n [0.02956944 0.97043056]\n [0.06685057 0.93314943]\n [0.24449056 0.75550944]\n [0.35342232 0.64657768]\n [0.08716714 0.91283286]\n [0.23173118 0.76826882]\n [0.07530269 0.92469731]\n [0.32480991 0.67519009]\n [0.54288755 0.45711245]\n [0.07527273 0.92472727]\n [0.41617511 0.58382489]\n [0.07530269 0.92469731]\n [0.22546558 0.77453442]\n [0.32471553 0.67528447]\n [0.07527273 0.92472727]]\n\n\n\nFor saga solver and C value = 0.01, \naccuracy is 78.57142857142857 %\nPredicted Probabilities ar:\n[[0.34684558 0.65315442]\n [0.29470284 0.70529716]\n [0.17787806 0.82212194]\n [0.20142354 0.79857646]\n [0.1831434  0.8168566 ]\n [0.18487204 0.81512796]\n [0.33101502 0.66898498]\n [0.32066723 0.67933277]\n [0.20142354 0.79857646]\n [0.33055598 0.66944402]\n [0.19766136 0.80233864]\n [0.33342712 0.66657288]\n [0.13571833 0.86428167]\n [0.20538661 0.79461339]\n [0.28083704 0.71916296]\n [0.14086757 0.85913243]\n [0.36848649 0.63151351]\n [0.17096487 0.82903513]\n [0.3386826  0.6613174 ]\n [0.18683095 0.81316905]\n [0.27687942 0.72312058]\n [0.33081472 0.66918528]\n [0.35759346 0.64240654]\n [0.31126613 0.68873387]\n [0.24925441 0.75074559]\n [0.35220081 0.64779919]\n [0.35489252 0.64510748]\n [0.22561584 0.77438416]\n [0.34132543 0.65867457]\n [0.13088204 0.86911796]\n [0.30503292 0.69496708]\n [0.2936852  0.7063148 ]\n [0.30458844 0.69541156]\n [0.32047019 0.67952981]\n [0.24264569 0.75735431]\n [0.29513902 0.70486098]\n [0.3386826  0.6613174 ]\n [0.15972188 0.84027812]\n [0.29632273 0.70367727]\n [0.30314595 0.69685405]\n [0.34397817 0.65602183]\n [0.18862682 0.81137318]\n [0.29532725 0.70467275]\n [0.35220081 0.64779919]\n [0.17264062 0.82735938]\n [0.34435996 0.65564004]\n [0.30753529 0.69246471]\n [0.33342712 0.66657288]\n [0.29269489 0.70730511]\n [0.29289095 0.70710905]\n [0.15576171 0.84423829]\n [0.31044523 0.68955477]\n [0.17929802 0.82070198]\n [0.32562121 0.67437879]\n [0.16554595 0.83445405]\n [0.1329256  0.8670744 ]\n [0.18327877 0.81672123]\n [0.26524552 0.73475448]\n [0.30503292 0.69496708]\n [0.19968032 0.80031968]\n [0.26220641 0.73779359]\n [0.1921178  0.8078822 ]\n [0.29513902 0.70486098]\n [0.37123134 0.62876866]\n [0.19043592 0.80956408]\n [0.33081472 0.66918528]\n [0.1921178  0.8078822 ]\n [0.25370739 0.74629261]\n [0.29288221 0.70711779]\n [0.19043592 0.80956408]]\n\n\n\nFor saga solver and C value = 0.5, \naccuracy is 74.28571428571429 %\nPredicted Probabilities ar:\n[[0.51119675 0.48880325]\n [0.38140364 0.61859636]\n [0.02933553 0.97066447]\n [0.04339459 0.95660541]\n [0.02953756 0.97046244]\n [0.03423871 0.96576129]\n [0.45149361 0.54850639]\n [0.41234997 0.58765003]\n [0.04339459 0.95660541]\n [0.4545565  0.5454435 ]\n [0.04019965 0.95980035]\n [0.44895982 0.55104018]\n [0.02039623 0.97960377]\n [0.04912084 0.95087916]\n [0.28287555 0.71712445]\n [0.01317589 0.98682411]\n [0.59001743 0.40998257]\n [0.02391731 0.97608269]\n [0.46877479 0.53122521]\n [0.03349931 0.96650069]\n [0.26676054 0.73323946]\n [0.43910881 0.56089119]\n [0.55092678 0.44907322]\n [0.40075895 0.59924105]\n [0.22094834 0.77905166]\n [0.53111107 0.46888893]\n [0.54103515 0.45896485]\n [0.17379847 0.82620153]\n [0.4787233  0.5212767 ]\n [0.00924108 0.99075892]\n [0.35862647 0.64137353]\n [0.3248035  0.6751965 ]\n [0.41970774 0.58029226]\n [0.40025537 0.59974463]\n [0.22285165 0.77714835]\n [0.32279597 0.67720403]\n [0.46877479 0.53122521]\n [0.01889788 0.98110212]\n [0.34485422 0.65514578]\n [0.34456366 0.65543634]\n [0.48868872 0.51131128]\n [0.03481566 0.96518434]\n [0.33385288 0.66614712]\n [0.53111107 0.46888893]\n [0.02486682 0.97513318]\n [0.49886589 0.50113411]\n [0.36785608 0.63214392]\n [0.44895982 0.55104018]\n [0.3141351  0.6858649 ]\n [0.32252281 0.67747719]\n [0.01766741 0.98233259]\n [0.39825951 0.60174049]\n [0.03909358 0.96090642]\n [0.41955744 0.58044256]\n [0.0432531  0.9567469 ]\n [0.01155264 0.98844736]\n [0.0310093  0.9689907 ]\n [0.22958645 0.77041355]\n [0.35862647 0.64137353]\n [0.04382151 0.95617849]\n [0.18489179 0.81510821]\n [0.03582651 0.96417349]\n [0.32279597 0.67720403]\n [0.59963459 0.40036541]\n [0.0361818  0.9638182 ]\n [0.43910881 0.56089119]\n [0.03582651 0.96417349]\n [0.20625125 0.79374875]\n [0.32503773 0.67496227]\n [0.0361818  0.9638182 ]]\n\n\n\nFor saga solver and C value = 0.05, \naccuracy is 78.57142857142857 %\nPredicted Probabilities ar:\n[[0.43996879 0.56003121]\n [0.34017957 0.65982043]\n [0.09267768 0.90732232]\n [0.1191794  0.8808206 ]\n [0.0942983  0.9057017 ]\n [0.10187516 0.89812484]\n [0.40167221 0.59832779]\n [0.37676278 0.62323722]\n [0.1191794  0.8808206 ]\n [0.40604028 0.59395972]\n [0.11378704 0.88621296]\n [0.40300248 0.59699752]\n [0.06008596 0.93991404]\n [0.12706644 0.87293356]\n [0.29240451 0.70759549]\n [0.05500119 0.94499881]\n [0.49208302 0.50791698]\n [0.08265189 0.91734811]\n [0.41567206 0.58432794]\n [0.10072706 0.89927294]\n [0.2793123  0.7206877 ]\n [0.39671477 0.60328523]\n [0.46593295 0.53406705]\n [0.36346106 0.63653894]\n [0.23922253 0.76077747]\n [0.45291885 0.54708115]\n [0.45941898 0.54058102]\n [0.19681083 0.80318917]\n [0.42205003 0.57794997]\n [0.04450774 0.95549226]\n [0.34470831 0.65529169]\n [0.31767885 0.68232115]\n [0.36408328 0.63591672]\n [0.37192167 0.62807833]\n [0.23107082 0.76892918]\n [0.32143369 0.67856631]\n [0.41567206 0.58432794]\n [0.07135421 0.92864579]\n [0.32792455 0.67207545]\n [0.33352764 0.66647236]\n [0.4284541  0.5715459 ]\n [0.10312545 0.89687455]\n [0.32595868 0.67404132]\n [0.45291885 0.54708115]\n [0.08466041 0.91533959]\n [0.43216177 0.56783823]\n [0.35065084 0.64934916]\n [0.40300248 0.59699752]\n [0.31574554 0.68425446]\n [0.32099584 0.67900416]\n [0.06630938 0.93369062]\n [0.36699896 0.63300104]\n [0.10243373 0.89756627]\n [0.38424304 0.61575696]\n [0.09718953 0.90281047]\n [0.04846617 0.95153383]\n [0.09607853 0.90392147]\n [0.25371674 0.74628326]\n [0.34470831 0.65529169]\n [0.11859988 0.88140012]\n [0.24658871 0.75341129]\n [0.10609776 0.89390224]\n [0.32143369 0.67856631]\n [0.49863293 0.50136707]\n [0.10557424 0.89442576]\n [0.39671477 0.60328523]\n [0.10609776 0.89390224]\n [0.23665897 0.76334103]\n [0.32022825 0.67977175]\n [0.10557424 0.89442576]]\n\n\n\nFor saga solver and C value = 0.02, \naccuracy is 78.57142857142857 %\nPredicted Probabilities ar:\n[[0.38770786 0.61229214]\n [0.31375887 0.68624113]\n [0.14067325 0.85932675]\n [0.1680016  0.8319984 ]\n [0.14469123 0.85530877]\n [0.1494517  0.8505483 ]\n [0.36281673 0.63718327]\n [0.34661295 0.65338705]\n [0.1680016  0.8319984 ]\n [0.36414796 0.63585204]\n [0.16311138 0.83688862]\n [0.36523628 0.63476372]\n [0.09790391 0.90209609]\n [0.17404777 0.82595223]\n [0.28819565 0.71180435]\n [0.09895144 0.90104856]\n [0.42180829 0.57819171]\n [0.13150009 0.86849991]\n [0.37348202 0.62651798]\n [0.15004978 0.84995022]\n [0.28045646 0.71954354]\n [0.36114253 0.63885747]\n [0.40464301 0.59535699]\n [0.3346686  0.6653314 ]\n [0.24582554 0.75417446]\n [0.39614431 0.60385569]\n [0.40038616 0.59961384]\n [0.2130818  0.7869182 ]\n [0.37763297 0.62236703]\n [0.08722077 0.91277923]\n [0.32422791 0.67577209]\n [0.30612547 0.69387453]\n [0.32920059 0.67079941]\n [0.34497305 0.65502695]\n [0.23754791 0.76245209]\n [0.30891203 0.69108797]\n [0.37348202 0.62651798]\n [0.11895458 0.88104542]\n [0.31145055 0.68854945]\n [0.31882251 0.68117749]\n [0.38180193 0.61819807]\n [0.15232121 0.84767879]\n [0.31046176 0.68953824]\n [0.39614431 0.60385569]\n [0.13353483 0.86646517]\n [0.38320119 0.61679881]\n [0.32811814 0.67188186]\n [0.36523628 0.63476372]\n [0.3051461  0.6948539 ]\n [0.3071205  0.6928795 ]\n [0.11362622 0.88637378]\n [0.33571152 0.66428848]\n [0.14561662 0.85438338]\n [0.35301573 0.64698427]\n [0.13379635 0.86620365]\n [0.09049034 0.90950966]\n [0.14559067 0.85440933]\n [0.26294836 0.73705164]\n [0.32422791 0.67577209]\n [0.16654583 0.83345417]\n [0.2589841  0.7410159 ]\n [0.1559918  0.8440082 ]\n [0.30891203 0.69108797]\n [0.42613102 0.57386898]\n [0.15462076 0.84537924]\n [0.36114253 0.63885747]\n [0.1559918  0.8440082 ]\n [0.24858019 0.75141981]\n [0.30668532 0.69331468]\n [0.15462076 0.84537924]]\n\n\n\nFor saga solver and C value = 0.2, \naccuracy is 75.71428571428571 %\nPredicted Probabilities ar:\n[[0.49345135 0.50654865]\n [0.37015832 0.62984168]\n [0.04455713 0.95544287]\n [0.06324809 0.93675191]\n [0.04485277 0.95514723]\n [0.05116632 0.94883368]\n [0.43928307 0.56071693]\n [0.40388031 0.59611969]\n [0.06324809 0.93675191]\n [0.44410743 0.55589257]\n [0.05907927 0.94092073]\n [0.43807322 0.56192678]\n [0.02959006 0.97040994]\n [0.07033844 0.92966156]\n [0.28709476 0.71290524]\n [0.02156198 0.97843802]\n [0.56569434 0.43430566]\n [0.03725941 0.96274059]\n [0.45602389 0.54397611]\n [0.04999098 0.95000902]\n [0.27076254 0.72923746]\n [0.42915534 0.57084466]\n [0.52972855 0.47027145]\n [0.39146609 0.60853391]\n [0.22656973 0.77343027]\n [0.51160523 0.48839477]\n [0.52067369 0.47932631]\n [0.1790812  0.8209188 ]\n [0.46504525 0.53495475]\n [0.01569024 0.98430976]\n [0.3571776  0.6428224 ]\n [0.32375498 0.67624502]\n [0.40461146 0.59538854]\n [0.39399527 0.60600473]\n [0.22428195 0.77571805]\n [0.32456172 0.67543828]\n [0.45602389 0.54397611]\n [0.03021297 0.96978703]\n [0.34095758 0.65904242]\n [0.34246841 0.65753159]\n [0.47408954 0.52591046]\n [0.05174399 0.94825601]\n [0.33366388 0.66633612]\n [0.51160523 0.48839477]\n [0.0385841  0.9614159 ]\n [0.48217992 0.51782008]\n [0.36555759 0.63444241]\n [0.43807322 0.56192678]\n [0.31665246 0.68334754]\n [0.32477004 0.67522996]\n [0.02792389 0.97207611]\n [0.39257021 0.60742979]\n [0.05584335 0.94415665]\n [0.41146232 0.58853768]\n [0.05847191 0.94152809]\n [0.01873686 0.98126314]\n [0.04665244 0.95334756]\n [0.23643578 0.76356422]\n [0.3571776  0.6428224 ]\n [0.06353982 0.93646018]\n [0.21384973 0.78615027]\n [0.05330651 0.94669349]\n [0.32456172 0.67543828]\n [0.57459359 0.42540641]\n [0.05355501 0.94644499]\n [0.42915534 0.57084466]\n [0.05330651 0.94669349]\n [0.21532951 0.78467049]\n [0.32563975 0.67436025]\n [0.05355501 0.94644499]]\n\n\n\n"
                }
            ],
            "source": "acc_dict = {}\nfor s in solvers:\n    for r in reg_par:\n        LR_obj = LogisticRegression(C=r,solver=s)\n        LR_obj.fit(X_train,y_train)\n        y_pred_log = LR_obj.predict(X_test) \n        key = (s,r)\n        acc_dict[key] = metrics.accuracy_score(y_test,y_pred_log)\n        print(\"For {} solver and C value = {}, \\naccuracy is {} %\\nPredicted Probabilities ar:\".format(s,r,acc_dict[key]*100))\n        print(LR_obj.predict_proba(X_test))\n        print('\\n\\n')"
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [],
            "source": "max_acc = max(list(acc_dict.values()))"
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.7857142857142857"
                    },
                    "execution_count": 33,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "max_acc"
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "{('newton-cg', 1): 0.7285714285714285,\n ('newton-cg', 0.1): 0.7714285714285715,\n ('newton-cg', 0.01): 0.7857142857142857,\n ('newton-cg', 0.5): 0.7428571428571429,\n ('newton-cg', 0.05): 0.7857142857142857,\n ('newton-cg', 0.02): 0.7857142857142857,\n ('newton-cg', 0.2): 0.7571428571428571,\n ('lbfgs', 1): 0.7285714285714285,\n ('lbfgs', 0.1): 0.7714285714285715,\n ('lbfgs', 0.01): 0.7857142857142857,\n ('lbfgs', 0.5): 0.7428571428571429,\n ('lbfgs', 0.05): 0.7857142857142857,\n ('lbfgs', 0.02): 0.7857142857142857,\n ('lbfgs', 0.2): 0.7571428571428571,\n ('liblinear', 1): 0.7142857142857143,\n ('liblinear', 0.1): 0.7428571428571429,\n ('liblinear', 0.01): 0.6857142857142857,\n ('liblinear', 0.5): 0.7285714285714285,\n ('liblinear', 0.05): 0.7428571428571429,\n ('liblinear', 0.02): 0.7285714285714285,\n ('liblinear', 0.2): 0.7285714285714285,\n ('sag', 1): 0.7285714285714285,\n ('sag', 0.1): 0.7714285714285715,\n ('sag', 0.01): 0.7857142857142857,\n ('sag', 0.5): 0.7428571428571429,\n ('sag', 0.05): 0.7857142857142857,\n ('sag', 0.02): 0.7857142857142857,\n ('sag', 0.2): 0.7571428571428571,\n ('saga', 1): 0.7285714285714285,\n ('saga', 0.1): 0.7714285714285715,\n ('saga', 0.01): 0.7857142857142857,\n ('saga', 0.5): 0.7428571428571429,\n ('saga', 0.05): 0.7857142857142857,\n ('saga', 0.02): 0.7857142857142857,\n ('saga', 0.2): 0.7571428571428571}"
                    },
                    "execution_count": 34,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "acc_dict"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Observations and Inferences from the above models\n\nAfter training the model with 4 different ML Algorithms, the following observations were made:\n- K-Nearest Neighbors algorithm (KNN) gave better accuracy with k value = 7\n- Decision Tree classifier gave a better accuracy with max_depth = 7\n- Support Vector Machine algorithm (SVM) gave better accuracy for kernel type \"Sigmoid\"\n- Logistic Regression algorithm gave better accuracies for multiple different parameters, like Newton-CG Solver with C = 0.05/0.02 (or) Saga Solver with C = 0.05/0.02 etc.\n\n**Note: The above observations do not guarantee that the model will work better for other datasets as well**\n    "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Model Evaluation using Test set"
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [],
            "source": "from sklearn.metrics import jaccard_similarity_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "First, download and load the test set:"
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "--2020-03-16 14:10:34--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_test.csv\nResolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\nConnecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3642 (3.6K) [text/csv]\nSaving to: \u2018loan_test.csv\u2019\n\n100%[======================================>] 3,642       --.-K/s   in 0s      \n\n2020-03-16 14:10:34 (358 MB/s) - \u2018loan_test.csv\u2019 saved [3642/3642]\n\n"
                }
            ],
            "source": "!wget -O loan_test.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_test.csv"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "### Load Test set for evaluation "
        },
        {
            "cell_type": "code",
            "execution_count": 93,
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Unnamed: 0.1</th>\n      <th>loan_status</th>\n      <th>Principal</th>\n      <th>terms</th>\n      <th>effective_date</th>\n      <th>due_date</th>\n      <th>age</th>\n      <th>education</th>\n      <th>Gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>9/8/2016</td>\n      <td>10/7/2016</td>\n      <td>50</td>\n      <td>Bechalor</td>\n      <td>female</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>5</td>\n      <td>PAIDOFF</td>\n      <td>300</td>\n      <td>7</td>\n      <td>9/9/2016</td>\n      <td>9/15/2016</td>\n      <td>35</td>\n      <td>Master or Above</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21</td>\n      <td>21</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>9/10/2016</td>\n      <td>10/9/2016</td>\n      <td>43</td>\n      <td>High School or Below</td>\n      <td>female</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>24</td>\n      <td>24</td>\n      <td>PAIDOFF</td>\n      <td>1000</td>\n      <td>30</td>\n      <td>9/10/2016</td>\n      <td>10/9/2016</td>\n      <td>26</td>\n      <td>college</td>\n      <td>male</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35</td>\n      <td>35</td>\n      <td>PAIDOFF</td>\n      <td>800</td>\n      <td>15</td>\n      <td>9/11/2016</td>\n      <td>9/25/2016</td>\n      <td>29</td>\n      <td>Bechalor</td>\n      <td>male</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   Unnamed: 0  Unnamed: 0.1 loan_status  Principal  terms effective_date  \\\n0           1             1     PAIDOFF       1000     30       9/8/2016   \n1           5             5     PAIDOFF        300      7       9/9/2016   \n2          21            21     PAIDOFF       1000     30      9/10/2016   \n3          24            24     PAIDOFF       1000     30      9/10/2016   \n4          35            35     PAIDOFF        800     15      9/11/2016   \n\n    due_date  age             education  Gender  \n0  10/7/2016   50              Bechalor  female  \n1  9/15/2016   35       Master or Above    male  \n2  10/9/2016   43  High School or Below  female  \n3  10/9/2016   26               college    male  \n4  9/25/2016   29              Bechalor    male  "
                    },
                    "execution_count": 93,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "test_df = pd.read_csv('loan_test.csv')\ntest_df.head()"
        },
        {
            "cell_type": "code",
            "execution_count": 94,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "(54, 10)"
                    },
                    "execution_count": 94,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "test_df.shape"
        },
        {
            "cell_type": "code",
            "execution_count": 95,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Principal</th>\n      <th>terms</th>\n      <th>age</th>\n      <th>Gender</th>\n      <th>weekend</th>\n      <th>Bechalor</th>\n      <th>High School or Below</th>\n      <th>college</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>50</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>300</td>\n      <td>7</td>\n      <td>35</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>43</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000</td>\n      <td>30</td>\n      <td>26</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>800</td>\n      <td>15</td>\n      <td>29</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   Principal  terms  age  Gender  weekend  Bechalor  High School or Below  \\\n0       1000     30   50       1        0         1                     0   \n1        300      7   35       0        0         0                     0   \n2       1000     30   43       1        0         0                     1   \n3       1000     30   26       0        1         0                     0   \n4        800     15   29       0        1         1                     0   \n\n   college  \n0        0  \n1        0  \n2        0  \n3        1  \n4        0  "
                    },
                    "execution_count": 95,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "test_df['effective_date'] = pd.to_datetime(df['effective_date'])\ntest_df['due_date'] = pd.to_datetime(df['due_date'])\ntest_df['dayofweek'] = test_df['effective_date'].dt.dayofweek\ntest_df['weekend'] = test_df['dayofweek'].apply(lambda x: 1 if (x>3)  else 0)\ntest_df['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\nfeature_set = test_df[['Principal','terms','age','Gender','weekend']]\nfeature_set = pd.concat([feature_set,pd.get_dummies(test_df['education'])], axis=1)\nfeature_set.drop(['Master or Above'], axis = 1,inplace=True)\nfeature_set.head()"
        },
        {
            "cell_type": "code",
            "execution_count": 96,
            "metadata": {},
            "outputs": [],
            "source": "X_final = feature_set\ny_final = test_df['loan_status'].values"
        },
        {
            "cell_type": "code",
            "execution_count": 97,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/ipykernel/__main__.py:1: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n  if __name__ == '__main__':\n"
                },
                {
                    "data": {
                        "text/plain": "array([[ 0.49362588,  0.92844966,  3.05981865,  1.97714211, -4.12310563,\n         2.39791576, -0.79772404, -0.86135677],\n       [-3.56269116, -1.70427745,  0.53336288, -0.50578054, -4.12310563,\n        -0.41702883, -0.79772404, -0.86135677],\n       [ 0.49362588,  0.92844966,  1.88080596,  1.97714211, -4.12310563,\n        -0.41702883,  1.25356634, -0.86135677],\n       [ 0.49362588,  0.92844966, -0.98251057, -0.50578054,  0.24253563,\n        -0.41702883, -0.79772404,  1.16095912],\n       [-0.66532184, -0.78854628, -0.47721942, -0.50578054,  0.24253563,\n         2.39791576, -0.79772404, -0.86135677]])"
                    },
                    "execution_count": 97,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "X_final= preprocessing.StandardScaler().fit(X_final).transform(X_final)\nX_final[0:5]"
        },
        {
            "cell_type": "code",
            "execution_count": 98,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array(['PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF', 'PAIDOFF'],\n      dtype=object)"
                    },
                    "execution_count": 98,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "y_final[0:5]"
        },
        {
            "cell_type": "code",
            "execution_count": 99,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "(54, 8)\n(54,)\n"
                }
            ],
            "source": "print(X_final.shape)\nprint(y_final.shape)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# For KNN Algorithm"
        },
        {
            "cell_type": "code",
            "execution_count": 100,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Jaccard Similarity Index of the Model: 68.51851851851852 %\n\nF1 Score of the Model:[0.19047619 0.8045977 ]\n\n\t\t\tClassification Report:\n\t\t-----------------------------------\n\n\n              precision    recall  f1-score   support\n\n  COLLECTION       0.14      0.29      0.19         7\n     PAIDOFF       0.88      0.74      0.80        47\n\n   micro avg       0.69      0.69      0.69        54\n   macro avg       0.51      0.52      0.50        54\nweighted avg       0.78      0.69      0.72        54\n\n"
                }
            ],
            "source": "neigh = KNeighborsClassifier(n_neighbors=7)\nneigh.fit(X_train,y_train)\ny_final_pred_knn = neigh.predict(X_final)\n#print(\"Accuracy of the model: {} %\\n\".format(metrics.accuracy_score(y_final_pred_knn,y_final)*100))\nprint('Jaccard Similarity Index of the Model: {} %\\n'.format(metrics.jaccard_similarity_score(y_final_pred_knn,y_final)*100))\nprint('F1 Score of the Model:{}\\n'.format(metrics.f1_score(y_final,y_final_pred_knn,average=None)))\nprint(\"\\t\\t\\tClassification Report:\\n\\t\\t-----------------------------------\\n\\n\")\nprint(metrics.classification_report(y_final_pred_knn,y_final))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# For Decision Tree Classifier"
        },
        {
            "cell_type": "code",
            "execution_count": 101,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Jaccard Similarity Index of the Model: 66.66666666666666 %\n\nF1 Score of the Model:[0.25       0.78571429]\n\n\t\t\tClassification Report:\n\t\t-----------------------------------\n\n\n              precision    recall  f1-score   support\n\n  COLLECTION       0.21      0.30      0.25        10\n     PAIDOFF       0.82      0.75      0.79        44\n\n   micro avg       0.67      0.67      0.67        54\n   macro avg       0.52      0.53      0.52        54\nweighted avg       0.71      0.67      0.69        54\n\n"
                }
            ],
            "source": "tree_obj = DecisionTreeClassifier(criterion = 'entropy',max_depth = 7)\ntree_obj.fit(X_train,y_train)\ny_final_pred_dectree = tree_obj.predict(X_final)\n#print(\"Accuracy of the model: {} %\\n\".format(metrics.accuracy_score(y_final_pred_dectree,y_final)*100))\nprint('Jaccard Similarity Index of the Model: {} %\\n'.format(metrics.jaccard_similarity_score(y_final_pred_dectree,y_final)*100))\nprint('F1 Score of the Model:{}\\n'.format(metrics.f1_score(y_final,y_final_pred_dectree,average=None)))\nprint(\"\\t\\t\\tClassification Report:\\n\\t\\t-----------------------------------\\n\\n\")\nprint(metrics.classification_report(y_final_pred_dectree,y_final))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# For SVM Algorithm"
        },
        {
            "cell_type": "code",
            "execution_count": 102,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Jaccard Similarity Index of the Model: 72.22222222222221 %\n\nF1 Score of the Model:[0.11764706 0.83516484]\n\n\t\t\tClassification Report:\n\t\t-----------------------------------\n\n\n              precision    recall  f1-score   support\n\n  COLLECTION       0.07      0.33      0.12         3\n     PAIDOFF       0.95      0.75      0.84        51\n\n   micro avg       0.72      0.72      0.72        54\n   macro avg       0.51      0.54      0.48        54\nweighted avg       0.90      0.72      0.80        54\n\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n  \"avoid this warning.\", FutureWarning)\n"
                }
            ],
            "source": "svm_obj = SVC(kernel = 'sigmoid')\nsvm_obj.fit(X_train,y_train)\ny_final_pred_svm = svm_obj.predict(X_final)\n#print(\"Accuracy of the model: {} %\\n\".format(metrics.accuracy_score(y_final_pred_svm,y_final)*100))\nprint('Jaccard Similarity Index of the Model: {} %\\n'.format(metrics.jaccard_similarity_score(y_final_pred_svm,y_final)*100))\nprint('F1 Score of the Model:{}\\n'.format(metrics.f1_score(y_final,y_final_pred_svm,average=None)))\nprint(\"\\t\\t\\tClassification Report:\\n\\t\\t-----------------------------------\\n\\n\")\nprint(metrics.classification_report(y_final_pred_svm,y_final))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# For Logistic Regression"
        },
        {
            "cell_type": "code",
            "execution_count": 115,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "FOR NEWTON-CG SOLVER AND C = 0.05:\n\nJaccard Similarity Index of the Model: 74.07407407407408 %\n\nF1 Score of the Model:[0.         0.85106383]\n\n\t\t\tClassification Report:\n\t\t-----------------------------------\n\n\n              precision    recall  f1-score   support\n\n  COLLECTION       0.00      0.00      0.00         0\n     PAIDOFF       1.00      0.74      0.85        54\n\n   micro avg       0.74      0.74      0.74        54\n   macro avg       0.50      0.37      0.43        54\nweighted avg       1.00      0.74      0.85        54\n\nLog Loss for the Model:0.6771451948936323 %\nFOR SAGA SOLVER AND C = 0.02:\n\nJaccard Similarity Index of the Model: 74.07407407407408 %\n\nF1 Score of the Model:[0.         0.85106383]\n\n\t\t\tClassification Report:\n\t\t-----------------------------------\n\n\n              precision    recall  f1-score   support\n\n  COLLECTION       0.00      0.00      0.00         0\n     PAIDOFF       1.00      0.74      0.85        54\n\n   micro avg       0.74      0.74      0.74        54\n   macro avg       0.50      0.37      0.43        54\nweighted avg       1.00      0.74      0.85        54\n\nLog Loss for the Model:0.6931471805599455 %\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n  'recall', 'true', average, warn_for)\n"
                }
            ],
            "source": "from sklearn.metrics import log_loss\n\n#For Newton-CG solver and C=0.05\nLR_obj = LogisticRegression(solver = 'newton-cg',C = 0.05)\nLR_obj.fit(X_train,y_train)\ny_final_pred_logreg = LR_obj.predict(X_final)\nprint('FOR NEWTON-CG SOLVER AND C = 0.05:\\n')\n#print(\"Accuracy of the model: {} %\\n\".format(metrics.accuracy_score(y_final_pred_logreg,y_final)*100))\nprint('Jaccard Similarity Index of the Model: {} %\\n'.format(metrics.jaccard_similarity_score(y_final_pred_logreg,y_final)*100))\nprint('F1 Score of the Model:{}\\n'.format(metrics.f1_score(y_final,y_final_pred_logreg,average=None)))\nprint(\"\\t\\t\\tClassification Report:\\n\\t\\t-----------------------------------\\n\\n\")\nprint(metrics.classification_report(y_final_pred_logreg,y_final))\ny_pred_prob_logreg = LR_obj.predict_proba(X_final)\nprint(\"Log Loss for the Model:{} %\".format(log_loss(y_final,y_pred_prob_logreg*100)))\n\n#For Saga solver and C=0.02\nLR_obj = LogisticRegression(solver = 'saga',C = 0.02)\nLR_obj.fit(X_train,y_train)\ny_final_pred_logreg = LR_obj.predict(X_final)\nprint('FOR SAGA SOLVER AND C = 0.02:\\n')\n#print(\"Accuracy of the model: {} %\\n\".format(metrics.accuracy_score(y_final_pred_logreg,y_final)*100))\nprint('Jaccard Similarity Index of the Model: {} %\\n'.format(metrics.jaccard_similarity_score(y_final_pred_logreg,y_final)*100))\nprint('F1 Score of the Model:{}\\n'.format(metrics.f1_score(y_final,y_final_pred_logreg,average=None)))\nprint(\"\\t\\t\\tClassification Report:\\n\\t\\t-----------------------------------\\n\\n\")\nprint(metrics.classification_report(y_final_pred_logreg,y_final))\ny_pred_prob_logreg = LR_obj.predict_proba(X_final)\nprint(\"Log Loss for the Model:{} %\".format(log_loss(y_final,y_pred_prob_logreg*100)))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Out of the two models in Logistic Regression, Log Loss for newton-cg solver is low and hence it predicts better than the saga solver.**"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Report\nYou should be able to report the accuracy of the built model using different evaluation metrics:"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Updated Report after building models:**\n\n| Algorithm          | Jaccard | F1-score | LogLoss |\n|--------------------|---------|----------|---------|\n| KNN                |        | ?        | NA      |\n| Decision Tree      | ?       | ?        | NA      |\n| SVM                | 0.7222  |         | NA      |\n| LogisticRegression | 0.7407  | 0.8510   | 0.6771 |"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "<h2>Want to learn more?</h2>\n\nIBM SPSS Modeler is a comprehensive analytics platform that has many machine learning algorithms. It has been designed to bring predictive intelligence to decisions made by individuals, by groups, by systems \u2013 by your enterprise as a whole. A free trial is available through this course, available here: <a href=\"http://cocl.us/ML0101EN-SPSSModeler\">SPSS Modeler</a>\n\nAlso, you can use Watson Studio to run these notebooks faster with bigger datasets. Watson Studio is IBM's leading cloud solution for data scientists, built by data scientists. With Jupyter notebooks, RStudio, Apache Spark and popular libraries pre-packaged in the cloud, Watson Studio enables data scientists to collaborate on their projects without having to install anything. Join the fast-growing community of Watson Studio users today with a free account at <a href=\"https://cocl.us/ML0101EN_DSX\">Watson Studio</a>\n\n<h3>Thanks for completing this lesson!</h3>\n\n<h4>Author:  <a href=\"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a></h4>\n<p><a href=\"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a>, PhD is a Data Scientist in IBM with a track record of developing enterprise level applications that substantially increases clients\u2019 ability to turn data into actionable knowledge. He is a researcher in data mining field and expert in developing advanced analytic methods like machine learning and statistical modelling on large datasets.</p>\n\n<hr>\n\n<p>Copyright &copy; 2018 <a href=\"https://cocl.us/DX0108EN_CC\">Cognitive Class</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>.</p>"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}